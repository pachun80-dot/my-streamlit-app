import io
import os
import re
import sys
import glob
import time
import threading
import unicodedata
import warnings
import pandas as pd
import streamlit as st
from openpyxl.styles import Alignment

# gRPC ê²½ê³  ì–µì œ
os.environ['GRPC_ENABLE_FORK_SUPPORT'] = '0'
os.environ['GRPC_POLL_STRATEGY'] = 'poll'
warnings.filterwarnings('ignore', category=FutureWarning)

from pdf_parser import (
    parse_pdf, split_articles, _detect_lang,
    extract_structured_articles, save_structured_to_excel
)
from html_parser import parse_eu_html_to_dataframe, parse_china_html_to_dataframe, parse_nz_html_to_dataframe, parse_taiwan_html_to_dataframe, parse_germany_html_to_dataframe, parse_russia_html_to_dataframe
from translator import translate_batch, _clean_translation_output
from embedder import (
    find_similar_korean,
    find_similar_korean_ai,
    find_similar_korean_batch,
    select_relevant_korean_laws,
)

# â”€â”€ í˜ì´ì§€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="ë²•ë ¹ ë²ˆì—­ ë¹„êµ ë¶„ì„ ì‹œìŠ¤í…œ",
    page_icon="",
    layout="wide",
    initial_sidebar_state="expanded",
)

# â”€â”€ ë°ì´í„° ê²½ë¡œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PROJECT_DIR = os.path.dirname(os.path.abspath(__file__))

if sys.platform == "win32":
    DATA_DIR = os.environ.get("DATA_DIR", r"C:\Users\milhi\Desktop\DATA")
else:
    DATA_DIR = os.environ.get("DATA_DIR", os.path.join(PROJECT_DIR, "DATA"))

COUNTRY_MAP = {
    "ë‚¨ì•„í”„ë¦¬ì¹´ê³µí™”êµ­": "SOUTH_AFRICA",
    "ë‰´ì§ˆëœë“œ": "NEWZEALAND",
    "ëŒ€ë§Œ": "TAIWAN",
    "ë…ì¼": "GERMANY",
    "ëŸ¬ì‹œì•„": "RUSSIA",
    "ë§ë ˆì´ì‹œì•„": "MALAYSIA",
    "ë¯¸êµ­": "USA",
    "ë² íŠ¸ë‚¨": "VIETNAM",
    "ë¸Œë¼ì§ˆ": "BRAZIL",
    "ì‚¬ìš°ë””ì•„ë¼ë¹„ì•„": "SAUDI_ARABIA",
    "ì‹±ê°€í¬ë¥´": "SINGAPORE",
    "ì•„í”„ë¦¬ì¹´ì§€ì‹ì¬ì‚°ê¶Œê¸°êµ¬": "OAPI",
    "ì˜êµ­": "UK",
    "ìœ ëŸ½(EPC)": "EPC",
    "ìœ ëŸ½ì—°í•©": "EU",
    "ì¸ë„": "INDIA",
    "ì¸ë„ë„¤ì‹œì•„": "INDONESIA",
    "ì¼ë³¸": "JAPAN",
    "ì¤‘êµ­": "CHINA",
    "ìºë‚˜ë‹¤": "CANADA",
    "íƒœêµ­": "THAILAND",
    "íŠ€ë¥´í‚¤ì—": "TURKIYE",
    "í”„ë‘ìŠ¤": "FRANCE",
    "í•œêµ­": "KOREA",
    "í˜¸ì£¼": "AUSTRALIA",
    "í™ì½©": "HONGKONG",
}

KOREA_FOLDER = "KOREA"


def _safe_join(*parts: str) -> str:
    """í•œê¸€ ê²½ë¡œ í˜¸í™˜ì„± ì²˜ë¦¬ (macOS NFD vs Linux NFC).

    macOSì—ì„œ Gitì— ì»¤ë°‹ëœ í•œê¸€ í´ë”ëª…ì€ NFD(ë¶„í•´í˜•)ë¡œ ì €ì¥ë  ìˆ˜ ìˆë‹¤.
    Linux(Streamlit Cloud)ì—ì„œëŠ” NFC(ì¡°í•©í˜•)ì™€ NFDê°€ ì„œë¡œ ë‹¤ë¥¸ ê²½ë¡œë¡œ ì·¨ê¸‰ë˜ë¯€ë¡œ,
    ì§ì ‘ êµ¬ì„±í•œ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•Šì„ ë•Œ ë¶€ëª¨ ë””ë ‰í† ë¦¬ë¥¼ ìŠ¤ìº”í•˜ì—¬ ì¼ì¹˜í•˜ëŠ” í•­ëª©ì„ ì°¾ëŠ”ë‹¤.
    """
    path = os.path.join(*parts)
    if os.path.exists(path):
        return path
    # NFC/NFD ë³€í™˜ ì‹œë„
    for form in ("NFC", "NFD"):
        normalized = unicodedata.normalize(form, path)
        if os.path.exists(normalized):
            return normalized
    # ë¶€ëª¨ ë””ë ‰í† ë¦¬ì—ì„œ ì´ë¦„ ë§¤ì¹­ ì‹œë„
    parent = os.path.dirname(path)
    target = unicodedata.normalize("NFC", os.path.basename(path))
    if os.path.isdir(parent):
        for entry in os.listdir(parent):
            if unicodedata.normalize("NFC", entry) == target:
                return os.path.join(parent, entry)
    return path


# â”€â”€ ì „ë¬¸ UI ìŠ¤íƒ€ì¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PROFESSIONAL_STYLE = """
<style>
/* â”€â”€ í…Œë§ˆ ë³€ìˆ˜ (ë¼ì´íŠ¸ ëª¨ë“œ ê¸°ë³¸) â”€â”€ */
:root {
    --bg-primary: #fefcfb;
    --bg-secondary: #ffffff;
    --bg-tertiary: #fdf8f6;
    --bg-sidebar: linear-gradient(180deg, #fdf8f6 0%, #ffffff 100%);
    --text-primary: #5a4e53;
    --text-heading: #4a3d42;
    --text-secondary: #8a7e84;
    --border-color: #e8ddd8;
    --border-subtle: #f0e8e4;
    --accent: #8b2240;
    --accent-light: #a3324f;
    --accent-dark: #5c1a2a;
    --card-shadow: rgba(0, 0, 0, 0.04);
    --input-bg: #ffffff;
    --tab-hover-bg: #fdf4f0;
    --tab-active-bg: white;
    --table-even-bg: #fafafa;
    --badge-success-bg: #dcfce7;
    --badge-success-text: #166534;
    --badge-warning-bg: #fef3c7;
    --badge-warning-text: #92400e;
    --badge-info-bg: #fce8ed;
    --badge-info-text: #7a1b33;
    --diff-bg: #fff8e1;
    --diff-border: #ffc107;
    --korea-bg: #e8f5e9;
    --korea-border: #4caf50;
    --alert-bg: #ffffff;
}

/* â”€â”€ ë‹¤í¬ ëª¨ë“œ â”€â”€ */
@media (prefers-color-scheme: dark) {
  :root {
    --bg-primary: #1a1a2e;
    --bg-secondary: #252540;
    --bg-tertiary: #2d2d48;
    --bg-sidebar: linear-gradient(180deg, #1e1e35 0%, #252540 100%);
    --text-primary: #ddd6d9;
    --text-heading: #ede7ea;
    --text-secondary: #a89da3;
    --border-color: #3e3e58;
    --border-subtle: #33334a;
    --accent: #d4587a;
    --accent-light: #e06b8a;
    --accent-dark: #a3324f;
    --card-shadow: rgba(0, 0, 0, 0.3);
    --input-bg: #2d2d48;
    --tab-hover-bg: #33334a;
    --tab-active-bg: #2d2d48;
    --table-even-bg: #2a2a44;
    --badge-success-bg: #1a3a2a;
    --badge-success-text: #86efac;
    --badge-warning-bg: #3d2e10;
    --badge-warning-text: #fcd34d;
    --badge-info-bg: #3a1a28;
    --badge-info-text: #f9a8c0;
    --diff-bg: #2e2a1a;
    --diff-border: #b8960e;
    --korea-bg: #1a2e1e;
    --korea-border: #388e3c;
    --alert-bg: #252540;
  }
}

/* ì „ì²´ í°íŠ¸ ë° í…Œë§ˆ ì ìš© */
@import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap');

.stApp {
    font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
    background-color: var(--bg-primary) !important;
    color: var(--text-primary) !important;
}

/* ë©”ì¸ ì½˜í…ì¸  ì˜ì—­ */
.stApp > header {
    background-color: var(--bg-primary) !important;
}

.main .block-container {
    background-color: var(--bg-primary) !important;
    color: var(--text-primary) !important;
}

/* ëª¨ë“  í…ìŠ¤íŠ¸ ìš”ì†Œ ê¸°ë³¸ ìƒ‰ìƒ */
.stApp p, .stApp span, .stApp label, .stApp div,
.stApp li, .stApp td, .stApp th, .stApp caption {
    color: var(--text-primary) !important;
}

.stApp h1, .stApp h2, .stApp h3, .stApp h4, .stApp h5, .stApp h6 {
    color: var(--text-heading) !important;
}

/* ë©”ì¸ í—¤ë”ëŠ” í°ìƒ‰ í…ìŠ¤íŠ¸ ìœ ì§€ (í¬ë¦¼ìŠ¨ ë°°ê²½) */
.stApp .main-header,
.stApp .main-header h1,
.stApp .main-header p,
.stApp .main-header span,
.stApp .main-header div {
    color: #ffffff !important;
}

/* ì‚¬ì´ë“œë°” ìŠ¤íƒ€ì¼ */
section[data-testid="stSidebar"] {
    background: var(--bg-sidebar) !important;
    border-right: 1px solid var(--border-color);
}

section[data-testid="stSidebar"] .block-container {
    padding-top: 2rem;
}

section[data-testid="stSidebar"] p,
section[data-testid="stSidebar"] span,
section[data-testid="stSidebar"] label,
section[data-testid="stSidebar"] div {
    color: var(--text-primary) !important;
}

/* ë¼ë””ì˜¤ ë²„íŠ¼ / ì²´í¬ë°•ìŠ¤ ë¼ë²¨ */
.stRadio label, .stCheckbox label {
    color: var(--text-primary) !important;
}

/* ì…€ë ‰íŠ¸ë°•ìŠ¤ / ë©€í‹°ì…€ë ‰íŠ¸ í…ìŠ¤íŠ¸ */
[data-baseweb="select"] span,
[data-baseweb="select"] div {
    color: var(--text-primary) !important;
}

/* ë©€í‹°ì…€ë ‰íŠ¸ íƒœê·¸ (ì„ íƒëœ í•­ëª©) */
[data-baseweb="tag"] {
    color: var(--text-primary) !important;
    background-color: var(--bg-tertiary) !important;
}
[data-baseweb="tag"] span {
    color: var(--text-primary) !important;
}

/* ë“œë¡­ë‹¤ìš´ ë©”ë‰´ / íŒì˜¤ë²„ */
[data-baseweb="popover"] {
    background-color: var(--bg-secondary) !important;
}
[data-baseweb="menu"],
[data-baseweb="popover"] ul {
    background-color: var(--bg-secondary) !important;
}
[data-baseweb="menu"] li,
[data-baseweb="menu"] li span,
[data-baseweb="menu"] li div {
    color: var(--text-primary) !important;
    background-color: var(--bg-secondary) !important;
}
[data-baseweb="menu"] li:hover,
[data-baseweb="menu"] li:hover span {
    background-color: var(--bg-tertiary) !important;
}

/* caption í…ìŠ¤íŠ¸ */
.stApp .stCaption, .stApp small,
.stApp [data-testid="stCaptionContainer"] p {
    color: var(--text-secondary) !important;
}

/* ì²´í¬ë°•ìŠ¤ ë‚´ë¶€ í…ìŠ¤íŠ¸ */
.stApp .stCheckbox span,
.stApp .stCheckbox label,
.stApp .stCheckbox div {
    color: var(--text-primary) !important;
}

/* divider */
.stApp hr {
    border-color: var(--border-color) !important;
}

/* warning/info/error ë©”ì‹œì§€ ë‚´ë¶€ í…ìŠ¤íŠ¸ */
.stApp .stAlert p,
.stApp .stAlert span,
.stApp .stAlert div {
    color: inherit !important;
}

/* ë©”ì¸ í—¤ë” */
.main-header {
    background: linear-gradient(135deg, var(--accent-dark) 0%, var(--accent) 50%, var(--accent-light) 100%);
    color: white;
    padding: 2rem 2.5rem;
    border-radius: 12px;
    margin-bottom: 2rem;
    box-shadow: 0 4px 12px -2px rgba(92, 26, 42, 0.25);
}

.main-header h1 {
    margin: 0;
    font-size: 2rem;
    font-weight: 700;
    letter-spacing: -0.02em;
}

.main-header p {
    margin: 0.5rem 0 0 0;
    font-size: 1rem;
    opacity: 0.92;
}

/* ì¹´ë“œ ìŠ¤íƒ€ì¼ */
.info-card {
    background: var(--bg-secondary) !important;
    padding: 1.5rem;
    border-radius: 10px;
    border: 1px solid var(--border-color);
    box-shadow: 0 1px 3px 0 var(--card-shadow);
    margin-bottom: 1rem;
}

.info-card h3 {
    color: var(--text-heading) !important;
    font-size: 1.1rem;
    font-weight: 600;
    margin-bottom: 0.5rem;
}

.info-card p {
    color: var(--text-secondary) !important;
}

/* ìƒíƒœ ë°°ì§€ */
.status-badge {
    display: inline-block;
    padding: 0.25rem 0.75rem;
    border-radius: 9999px;
    font-size: 0.875rem;
    font-weight: 500;
    margin: 0.25rem;
}

.status-success {
    background: var(--badge-success-bg) !important;
    color: var(--badge-success-text) !important;
}

.status-warning {
    background: var(--badge-warning-bg) !important;
    color: var(--badge-warning-text) !important;
}

.status-info {
    background: var(--badge-info-bg) !important;
    color: var(--badge-info-text) !important;
}

/* ë²„íŠ¼ ê°œì„  (í¬ë¦¼ìŠ¨ ë°°ê²½) */
.stApp .stButton > button {
    background: linear-gradient(135deg, var(--accent) 0%, #6e1a33 100%) !important;
    color: #ffffff !important;
    border: none;
    border-radius: 8px;
    padding: 0.6rem 1.5rem;
    font-weight: 600;
    font-size: 0.95rem;
    transition: all 0.2s;
    box-shadow: 0 2px 6px rgba(139, 34, 64, 0.2);
}
.stApp .stButton > button span,
.stApp .stButton > button div,
.stApp .stButton > button p { color: #ffffff !important; }

.stApp .stButton > button:hover {
    background: linear-gradient(135deg, #6e1a33 0%, var(--accent-dark) 100%) !important;
    color: #ffffff !important;
    box-shadow: 0 4px 10px rgba(139, 34, 64, 0.3);
    transform: translateY(-1px);
}

/* ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ (ì´ˆë¡ ë°°ê²½) */
.stApp .stDownloadButton > button {
    background: linear-gradient(135deg, #4a6741 0%, #3b5534 100%) !important;
    color: #ffffff !important;
    border: none;
    border-radius: 8px;
    padding: 0.6rem 1.5rem;
    font-weight: 600;
    font-size: 0.95rem;
    box-shadow: 0 2px 4px rgba(74, 103, 65, 0.2);
}
.stApp .stDownloadButton > button span,
.stApp .stDownloadButton > button div,
.stApp .stDownloadButton > button p { color: #ffffff !important; }

.stApp .stDownloadButton > button:hover {
    background: linear-gradient(135deg, #3b5534 0%, #2d422a 100%) !important;
    color: #ffffff !important;
    box-shadow: 0 4px 8px rgba(74, 103, 65, 0.3);
    transform: translateY(-1px);
}

/* ì…ë ¥ í•„ë“œ */
.stSelectbox, .stMultiselect, .stTextInput {
    border-radius: 8px;
}

.stSelectbox > div > div, .stMultiselect > div > div, .stTextInput > div > div {
    border-radius: 8px;
    border-color: var(--border-color);
    background-color: var(--input-bg) !important;
    color: var(--text-primary) !important;
}

.stSelectbox > div > div:focus-within, .stMultiselect > div > div:focus-within {
    border-color: var(--accent);
    box-shadow: 0 0 0 1px var(--accent);
}

/* í…ìŠ¤íŠ¸ ì…ë ¥ */
.stTextInput input, .stTextArea textarea {
    background-color: var(--input-bg) !important;
    color: var(--text-primary) !important;
}

/* ë©”íŠ¸ë¦­ ì¹´ë“œ */
.stMetric {
    background: var(--bg-secondary) !important;
    padding: 1rem;
    border-radius: 10px;
    border: 1px solid var(--border-color);
    box-shadow: 0 1px 2px 0 var(--card-shadow);
}

.stMetric label, .stMetric [data-testid="stMetricValue"],
.stMetric [data-testid="stMetricLabel"] {
    color: var(--text-primary) !important;
}

/* íƒ­ ìŠ¤íƒ€ì¼ */
.stTabs [data-baseweb="tab-list"] {
    gap: 8px;
    background: transparent;
    border-bottom: 2px solid var(--border-color);
}

.stTabs [data-baseweb="tab"] {
    background: transparent;
    border-radius: 8px 8px 0 0;
    padding: 0.75rem 1.5rem;
    font-weight: 500;
    color: var(--text-secondary) !important;
}

.stTabs [data-baseweb="tab"]:hover {
    background: var(--tab-hover-bg);
    color: var(--text-heading) !important;
}

.stTabs [aria-selected="true"] {
    background: var(--tab-active-bg);
    color: var(--accent) !important;
    border-bottom: 3px solid var(--accent);
}

/* í”„ë¡œê·¸ë ˆìŠ¤ ë°” - íŠ¸ë™ (ë°°ê²½) */
.stProgress > div > div > div {
    background-color: var(--border-color) !important;
    border-radius: 9999px;
}
/* í”„ë¡œê·¸ë ˆìŠ¤ ë°” - ì±„ì›€ (ì§„í–‰) */
.stProgress > div > div > div > div {
    background: linear-gradient(90deg, var(--accent) 0%, var(--accent-light) 100%) !important;
    border-radius: 9999px;
}

/* ì•Œë¦¼ ë°•ìŠ¤ */
.stAlert {
    border-radius: 10px;
    border-left: 4px solid;
    background-color: var(--alert-bg) !important;
}

/* ë°ì´í„°í”„ë ˆì„ í…Œì´ë¸” */
.dataframe {
    border: 1px solid var(--border-color) !important;
    border-radius: 8px;
    overflow: hidden;
}

.dataframe thead tr th {
    background: var(--bg-tertiary) !important;
    color: var(--text-heading) !important;
    font-weight: 600 !important;
    border-bottom: 2px solid var(--border-color) !important;
}

.dataframe tbody tr td {
    background: var(--bg-secondary) !important;
    color: var(--text-primary) !important;
}

/* ì‚¬ì´ë“œë°” ë¡œê³  ì˜ì—­ */
.sidebar-logo {
    text-align: center;
    padding: 1.5rem 1rem 1.5rem 1rem;
    margin-bottom: 1.5rem;
    background: linear-gradient(135deg, var(--accent-dark) 0%, var(--accent) 100%);
    border-radius: 10px;
    margin: 0 0.5rem 1.5rem 0.5rem;
}

section[data-testid="stSidebar"] .sidebar-logo h2,
.stApp .sidebar-logo h2 {
    color: #ffffff !important;
    font-size: 1.4rem;
    font-weight: 700;
    margin: 0;
    letter-spacing: 0.02em;
}

section[data-testid="stSidebar"] .sidebar-logo p,
.stApp .sidebar-logo p {
    color: rgba(255,255,255,0.85) !important;
    font-size: 0.82rem;
    margin: 0.3rem 0 0 0;
    font-weight: 400;
}

/* ì„¹ì…˜ í—¤ë” */
.section-header {
    display: flex;
    align-items: center;
    gap: 0.5rem;
    padding: 0 0 0.75rem 0;
    border-bottom: 3px solid var(--accent);
    margin-bottom: 1.5rem;
}

.section-header h3 {
    color: var(--text-heading) !important;
    font-size: 1.3rem;
    font-weight: 700;
    margin: 0;
    letter-spacing: -0.01em;
}

/* expander */
.streamlit-expanderHeader {
    background-color: var(--bg-secondary) !important;
    color: var(--text-primary) !important;
}

.streamlit-expanderContent {
    background-color: var(--bg-secondary) !important;
    color: var(--text-primary) !important;
}

/* status ìœ„ì ¯ */
[data-testid="stStatusWidget"] {
    background-color: var(--bg-secondary) !important;
    color: var(--text-primary) !important;
}
</style>
"""

st.markdown(PROFESSIONAL_STYLE, unsafe_allow_html=True)

# â”€â”€ ë©”ì¸ í—¤ë” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("""
<div class="main-header">
    <h1>ë²•ë ¹ ë²ˆì—­ ë¹„êµ ë¶„ì„ ì‹œìŠ¤í…œ</h1>
    <p>ë‹¤êµ­ì–´ íŠ¹í—ˆë²•ì„ AI ë²ˆì—­í•˜ê³  í•œêµ­ë²•ê³¼ ë¹„êµ ë¶„ì„í•˜ëŠ” ì „ë¬¸ í”Œë«í¼</p>
</div>
""", unsafe_allow_html=True)


# â”€â”€ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _list_pdfs(folder: str) -> list[str]:
    """PDF, XML, RTF íŒŒì¼ ëª©ë¡ì„ ë°˜í™˜í•œë‹¤."""
    path = os.path.join(DATA_DIR, folder)
    if not os.path.isdir(path):
        return []
    pdfs = glob.glob(os.path.join(path, "*.pdf"))
    xmls = glob.glob(os.path.join(path, "*.xml"))
    rtfs = glob.glob(os.path.join(path, "*.rtf"))
    return sorted(pdfs + xmls + rtfs)


def _list_result_files() -> list[str]:
    """ë²ˆì—­ ê²°ê³¼ Excel íŒŒì¼ ëª©ë¡ì„ ë°˜í™˜í•œë‹¤."""
    files = []
    translation_dir = _safe_join(DATA_DIR, "output", "ë²ˆì—­ë¹„êµê²°ê³¼")

    # êµ­ê°€ë³„ í•˜ìœ„ í´ë”ì—ì„œ ê²€ìƒ‰ (NFC/NFD í˜¸í™˜ ë°©ì‹)
    if os.path.isdir(translation_dir):
        for entry in sorted(os.listdir(translation_dir)):
            country_dir = _safe_join(translation_dir, entry)
            if os.path.isdir(country_dir):
                files.extend(_safe_glob(country_dir, "*.xlsx"))

        # í•˜ìœ„ í˜¸í™˜ì„±: ë²ˆì—­ë¹„êµê²°ê³¼ í´ë” ë£¨íŠ¸ì˜ íŒŒì¼ë„ í¬í•¨
        files.extend(_safe_glob(translation_dir, "*.xlsx"))

    # í•˜ìœ„ í˜¸í™˜ì„±: ê¸°ì¡´ output í´ë”ì˜ ë²ˆì—­ íŒŒì¼ë„ í¬í•¨
    output_dir = _safe_join(DATA_DIR, "output")
    if os.path.isdir(output_dir):
        files.extend(_safe_glob(output_dir, "ë²ˆì—­ë¹„êµ_*.xlsx"))

    # ì¤‘ë³µ ì œê±° ë° ìµœì‹ ìˆœ ì •ë ¬
    files = list(dict.fromkeys(files))
    def _safe_mtime(f):
        try:
            return os.path.getmtime(f)
        except Exception:
            return 0
    return sorted([f for f in files if not _basename(f).startswith("~$")],
                  key=_safe_mtime, reverse=True)


def _safe_glob(directory: str, pattern: str) -> list[str]:
    """í•œê¸€ íŒŒì¼ëª… í˜¸í™˜ glob. NFC/NFD ì •ê·œí™” ë¬¸ì œë¥¼ ìš°íšŒí•œë‹¤."""
    results = glob.glob(os.path.join(directory, pattern))
    if results:
        return results
    # glob ì‹¤íŒ¨ ì‹œ os.listdir + fnmatchë¡œ NFC ë¹„êµ
    import fnmatch
    try:
        entries = os.listdir(directory)
    except OSError:
        return []
    nfc_pattern = unicodedata.normalize("NFC", pattern)
    matched = []
    for entry in entries:
        nfc_entry = unicodedata.normalize("NFC", entry)
        if fnmatch.fnmatch(nfc_entry, nfc_pattern):
            matched.append(os.path.join(directory, entry))
    return matched


def _list_structured_excels() -> list[str]:
    """êµ¬ì¡°í™”ë²•ë¥  í´ë” ë‚´ êµ¬ì¡°í™” ì—‘ì…€ íŒŒì¼ ëª©ë¡ (í•œêµ­ë²• ì œì™¸)."""
    structured_dir = _safe_join(DATA_DIR, "output", "êµ¬ì¡°í™”ë²•ë¥ ")
    files = []

    # êµ­ê°€ë³„ í•˜ìœ„ í´ë”ì—ì„œ ê²€ìƒ‰ (í•œêµ­ ì œì™¸)
    if os.path.isdir(structured_dir):
        for country in COUNTRY_MAP.keys():
            if country == 'í•œêµ­':
                continue
            country_dir = os.path.join(structured_dir, country)
            if os.path.isdir(country_dir):
                files.extend(glob.glob(os.path.join(country_dir, "*.xlsx")))

        # í•˜ìœ„ í˜¸í™˜ì„±: êµ¬ì¡°í™”ë²•ë¥  í´ë” ë£¨íŠ¸ì˜ íŒŒì¼ë„ í¬í•¨
        files.extend(_safe_glob(structured_dir, "êµ¬ì¡°í™”_*.xlsx"))
        files.extend(_safe_glob(structured_dir, "EU_*.xlsx"))

    # í•˜ìœ„ í˜¸í™˜ì„±: ê¸°ì¡´ output í´ë”ì˜ êµ¬ì¡°í™” íŒŒì¼ë„ í¬í•¨
    output_dir = _safe_join(DATA_DIR, "output")
    if os.path.isdir(output_dir):
        files.extend(_safe_glob(output_dir, "êµ¬ì¡°í™”_*.xlsx"))

    all_files = sorted(
        [f for f in files if not _basename(f).startswith("~$")],
        key=os.path.getmtime, reverse=True,
    )
    # í•œêµ­ë²• êµ¬ì¡°í™” ì—‘ì…€ ì œì™¸
    nfc = unicodedata.normalize
    return [f for f in all_files
            if "í•œêµ­" not in nfc("NFC", _basename(f)) and "KOREA" not in _basename(f).upper()]


def _list_korea_excels() -> list[str]:
    """êµ¬ì¡°í™”ë²•ë¥  í´ë” ë‚´ í•œêµ­ë²• êµ¬ì¡°í™” ì—‘ì…€ íŒŒì¼ ëª©ë¡."""
    structured_dir = _safe_join(DATA_DIR, "output", "êµ¬ì¡°í™”ë²•ë¥ ")
    files = []

    # í•œêµ­ í•˜ìœ„ í´ë”ì—ì„œ ê²€ìƒ‰
    if os.path.isdir(structured_dir):
        korea_dir = os.path.join(structured_dir, "í•œêµ­")
        if os.path.isdir(korea_dir):
            files.extend(glob.glob(os.path.join(korea_dir, "*.xlsx")))

        # í•˜ìœ„ í˜¸í™˜ì„±: êµ¬ì¡°í™”ë²•ë¥  í´ë” ë£¨íŠ¸ì˜ í•œêµ­ë²• íŒŒì¼ë„ í¬í•¨
        files.extend(_safe_glob(structured_dir, "êµ¬ì¡°í™”_í•œêµ­_*.xlsx"))

    # í•˜ìœ„ í˜¸í™˜ì„±: ê¸°ì¡´ output í´ë”ë„ í™•ì¸
    output_dir = _safe_join(DATA_DIR, "output")
    if os.path.isdir(output_dir):
        files.extend(_safe_glob(output_dir, "êµ¬ì¡°í™”_í•œêµ­_*.xlsx"))

    return sorted(
        [f for f in files if not _basename(f).startswith("~$")],
        key=os.path.getmtime, reverse=True,
    )


def _basename(path: str) -> str:
    return os.path.basename(path)


def _detect_country_from_filename(filename: str) -> str:
    """íŒŒì¼ëª…ì—ì„œ êµ­ê°€ë¥¼ ê°ì§€í•œë‹¤.

    Returns:
        êµ­ê°€ëª… ë˜ëŠ” ë¹ˆ ë¬¸ìì—´
    """
    filename_lower = filename.lower()

    # íŒŒì¼ëª… íŒ¨í„´ ë§¤ì¹­ (êµ¬ì²´ì ì¸ í‚¤ì›Œë“œ â†’ ì¼ë°˜ì ì¸ í‚¤ì›Œë“œ ìˆœì„œ)
    _COUNTRY_KEYWORDS = [
        ('ì¼ë³¸', ['japan', 'ì¼ë³¸', '334ac']),
        ('ì¤‘êµ­', ['china', 'ì¤‘êµ­', 'cnipa']),
        ('ë¯¸êµ­', ['usa', 'united states', 'ë¯¸êµ­', 'title35', 'westlaw']),
        ('ìœ ëŸ½(EPC)', ['epc', 'european patent']),
        ('ìœ ëŸ½ì—°í•©', ['eu_', 'ìœ ëŸ½ì—°í•©']),
        ('ë…ì¼', ['germany', 'ë…ì¼', 'bjnr']),
        ('ì˜êµ­', ['uk', 'united kingdom', 'ì˜êµ­']),
        ('í”„ë‘ìŠ¤', ['france', 'í”„ë‘ìŠ¤']),
        ('ì¸ë„ë„¤ì‹œì•„', ['indonesia', 'ì¸ë„ë„¤ì‹œì•„']),
        ('ì¸ë„', ['india', 'ì¸ë„']),
        ('ë² íŠ¸ë‚¨', ['vietnam', 'ë² íŠ¸ë‚¨']),
        ('ë¸Œë¼ì§ˆ', ['brazil', 'ë¸Œë¼ì§ˆ']),
        ('ëŸ¬ì‹œì•„', ['russia', 'ëŸ¬ì‹œì•„']),
        ('ì‹±ê°€í¬ë¥´', ['singapore', 'ì‹±ê°€í¬ë¥´']),
        ('í˜¸ì£¼', ['australia', 'í˜¸ì£¼']),
        ('ëŒ€ë§Œ', ['taiwan', 'ëŒ€ë§Œ']),
        ('íƒœêµ­', ['thailand', 'íƒœêµ­']),
        ('ì•„í”„ë¦¬ì¹´ì§€ì‹ì¬ì‚°ê¶Œê¸°êµ¬', ['oapi', 'ì•„í”„ë¦¬ì¹´ì§€ì‹ì¬ì‚°ê¶Œ']),
        ('ë‚¨ì•„í”„ë¦¬ì¹´ê³µí™”êµ­', ['south africa', 'ë‚¨ì•„í”„ë¦¬ì¹´']),
        ('ì‚¬ìš°ë””ì•„ë¼ë¹„ì•„', ['saudi', 'ì‚¬ìš°ë””']),
        ('ìºë‚˜ë‹¤', ['canada', 'ìºë‚˜ë‹¤']),
        ('ë§ë ˆì´ì‹œì•„', ['malaysia', 'ë§ë ˆì´ì‹œì•„']),
        ('íŠ€ë¥´í‚¤ì—', ['turkiye', 'turkey', 'íŠ€ë¥´í‚¤ì—']),
        ('í™ì½©', ['hongkong', 'hong kong', 'í™ì½©', 'cap ']),
        ('ë‰´ì§ˆëœë“œ', ['newzealand', 'new zealand', 'ë‰´ì§ˆëœë“œ']),
        ('í•œêµ­', ['korea', 'í•œêµ­']),
    ]

    for country, keywords in _COUNTRY_KEYWORDS:
        for kw in keywords:
            if kw in filename or kw in filename_lower:
                return country

    return ''


def _country_to_folder_name(country: str) -> str:
    """êµ­ê°€ëª…ì„ í´ë”ëª…ìœ¼ë¡œ ë³€í™˜í•œë‹¤.

    Args:
        country: _detect_country_from_filename()ì´ ë°˜í™˜í•œ êµ­ê°€ëª…

    Returns:
        ì‹¤ì œ í´ë”ëª…
    """
    # íŠ¹ìˆ˜ ë§¤í•‘ (ê´„í˜¸ ì œê±° ë“±)
    _FOLDER_MAPPING = {
        'ìœ ëŸ½(EPC)': 'ìœ ëŸ½',
    }

    return _FOLDER_MAPPING.get(country, country)


def _korean_law_name(source: str) -> str:
    """PDF/Excel íŒŒì¼ëª…ì—ì„œ í•œêµ­ë²• ëª…ì¹­ ì¶”ì¶œ. ì˜ˆ: 'êµ¬ì¡°í™”_í•œêµ­_íŠ¹í—ˆë²•(ë²•ë¥ )(...).xlsx' â†’ 'í•œêµ­_íŠ¹í—ˆë²•'"""
    name = source.replace(".pdf", "").replace(".PDF", "").replace(".xlsx", "").replace(".XLSX", "").replace(".rtf", "").replace(".RTF", "")
    if "(" in name:
        name = name[:name.index("(")]
    name = name.strip()

    # "êµ¬ì¡°í™”_í•œêµ­_" ì ‘ë‘ì‚¬ ì œê±°
    if name.startswith("êµ¬ì¡°í™”_í•œêµ­_"):
        name = name.replace("êµ¬ì¡°í™”_í•œêµ­_", "í•œêµ­_", 1)
    elif name.startswith("êµ¬ì¡°í™”_"):
        name = name.replace("êµ¬ì¡°í™”_", "", 1)

    # ì´ë¯¸ "í•œêµ­"ìœ¼ë¡œ ì‹œì‘í•˜ì§€ ì•Šìœ¼ë©´ "í•œêµ­_" ì¶”ê°€
    if not name.startswith("í•œêµ­"):
        name = f"í•œêµ­_{name}"

    return name if name else "í•œêµ­ë²•"


def _article_num_display(article_num: str) -> str:
    """ì¡°ë¬¸ë²ˆí˜¸ UI í‘œì‹œìš© ë³€í™˜: 'Section N' / 'Article N' / 'Â§ N' â†’ 'N' (ë‚´ë¶€ ë°ì´í„°ëŠ” ë³€ê²½í•˜ì§€ ì•ŠìŒ)."""
    s = str(article_num).strip()
    m = re.match(r'^(?:Section|Article|Rule|Â§)\s*(.+)$', s, re.IGNORECASE)
    return m.group(1).strip() if m else s


def _clean_text(text: str) -> str:
    """ë²•ë¥  ì¡°ë¬¸ê³¼ ê´€ë ¨ ì—†ëŠ” í…ìŠ¤íŠ¸ì™€ ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸ë¥¼ ì œê±°í•œë‹¤."""
    if not text or not isinstance(text, str):
        return ""
    s = text.strip()
    # ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸ ì œê±°
    s = re.sub(r"[*_#`~>|]", "", s)
    s = re.sub(r"\[([^\]]*)\]\([^)]*\)", r"\1", s)  # [text](url) â†’ text
    # í˜ì´ì§€ ë²ˆí˜¸ / ë¨¸ë¦¬ê¸€ / ë°”ë‹¥ê¸€ íŒ¨í„´ ì œê±°
    s = re.sub(r"(?m)^[-â”€â”=]{3,}$", "", s)
    s = re.sub(r"(?m)^Page\s*\d+.*$", "", s, flags=re.IGNORECASE)
    s = re.sub(r"(?m)^-\s*\d+\s*-\s*$", "", s)
    s = re.sub(r"(?m)^åˆ—å°æ™‚é–“[ï¼š:].*$", "", s)
    s = re.sub(r"(?m)^æ‰€æœ‰æ¢æ–‡\s*$", "", s)
    s = re.sub(r"(?m)^æ³•è¦åç¨±[ï¼š:].*$", "", s)
    s = re.sub(r"(?m)^ä¿®æ­£æ—¥æœŸ[ï¼š:].*$", "", s)
    s = re.sub(r"(?m)^ä¿®æ­£â½‡æœŸ[ï¼š:].*$", "", s)
    s = re.sub(r"(?m)^æ³•è¦é¡åˆ¥[ï¼š:].*$", "", s)
    # ì—°ì† ë¹ˆ ì¤„ ì •ë¦¬
    s = re.sub(r"\n{3,}", "\n\n", s)
    return s.strip()


def _esc(text: str) -> str:
    """HTML ì´ìŠ¤ì¼€ì´í”„."""
    return text.replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;")


# â”€â”€ ê³µí†µ ìŠ¤íƒ€ì¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DETAIL_STYLE = """
<style>
.article-container {
    display: flex;
    margin-bottom: 20px;
    gap: 16px;
}
.article-structure {
    flex: 0 0 280px;
    background: var(--bg-tertiary) !important;
    border: 1px solid var(--border-color);
    border-radius: 8px;
    padding: 14px;
}
.structure-title {
    font-weight: 700;
    font-size: 0.95em;
    color: var(--text-heading) !important;
    margin-bottom: 8px;
    padding-bottom: 6px;
    border-bottom: 1px solid var(--border-color);
    background-color: transparent !important;
}
.structure-content {
    font-size: 0.88em;
    line-height: 1.8;
    color: var(--text-primary) !important;
    background-color: transparent !important;
    white-space: pre-wrap;
    word-break: break-word;
}
.article-row {
    display: flex;
    border: 1px solid var(--border-color);
    border-radius: 8px;
    overflow: hidden;
    flex: 1;
    background-color: var(--bg-secondary) !important;
}
.article-col {
    flex: 1;
    padding: 12px 16px;
    border-right: 2px solid var(--border-color);
    min-width: 0;
    background-color: var(--bg-secondary) !important;
    color: var(--text-primary) !important;
}
.article-col:last-child { border-right: none; }
.article-col-header {
    font-weight: 700; font-size: 0.95em;
    margin-bottom: 8px; padding-bottom: 6px;
    border-bottom: 1px solid var(--border-color);
}
.col-original .article-col-header { color: var(--accent) !important; }
.col-gemini .article-col-header { color: #b8860b !important; }
.col-claude .article-col-header { color: var(--accent-dark) !important; }
.article-col-body {
    font-size: 0.9em; line-height: 1.6;
    white-space: pre-wrap; word-break: break-word;
    color: var(--text-primary) !important; background-color: var(--bg-secondary) !important;
}
.diff-box {
    background: var(--diff-bg) !important; border-left: 4px solid var(--diff-border);
    padding: 10px 14px; margin: 8px 0;
    border-radius: 0 6px 6px 0; font-size: 0.9em; line-height: 1.6;
    color: var(--text-primary) !important;
}
.diff-box strong { color: var(--text-heading) !important; }
.korea-law-box {
    background: var(--korea-bg) !important; border-left: 4px solid var(--korea-border);
    padding: 10px 14px; margin: 8px 0;
    border-radius: 0 6px 6px 0; font-size: 0.9em; line-height: 1.6;
    color: var(--text-primary) !important;
}
.korea-law-box strong { color: var(--text-heading) !important; }
.article-title { font-size: 1.1em; font-weight: 700; margin-bottom: 6px; color: var(--text-heading) !important; }
/* ì „ì²´ ë³´ê¸° í…Œì´ë¸” */
.fullview-table { width: 100%; border-collapse: collapse; table-layout: fixed; }
.fullview-table th {
    background: var(--bg-tertiary) !important; padding: 10px 12px;
    border: 1px solid var(--border-color); text-align: left;
    position: sticky; top: 0; z-index: 1;
    color: var(--text-heading) !important;
}
.fullview-table td {
    padding: 10px 12px; border: 1px solid var(--border-color);
    vertical-align: top; white-space: pre-wrap;
    word-break: break-word; font-size: 0.88em; line-height: 1.6;
    color: var(--text-primary) !important; background-color: var(--bg-secondary) !important;
}
.fullview-table tr:nth-child(even) { background: var(--table-even-bg) !important; }
.fullview-table tr:nth-child(even) td { background: var(--table-even-bg) !important; }
.fullview-table col.col-id { width: 10% !important; max-width: 10% !important; }
.fullview-table col.col-text { width: 30% !important; max-width: 30% !important; }
.fullview-table col.col-text-narrow { width: 22.5% !important; max-width: 22.5% !important; }
.fullview-table col.col-korean { width: 22.5% !important; max-width: 22.5% !important; }
</style>
"""

# â”€â”€ ì‚¬ì´ë“œë°” ë„¤ë¹„ê²Œì´ì…˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    # ì‚¬ì´ë“œë°” ë¡œê³ 
    st.markdown("""
    <div class="sidebar-logo">
        <h2>LegalAI</h2>
        <p>ë²•ë ¹ ë²ˆì—­ ë¶„ì„ í”Œë«í¼</p>
    </div>
    """, unsafe_allow_html=True)

    # API í‚¤ ìƒíƒœ
    st.markdown("### ì‹œìŠ¤í…œ ìƒíƒœ")

    try:
        gemini_api = st.secrets.get("GOOGLE_API_KEY", "")
    except Exception:
        gemini_api = ""
    try:
        claude_api = st.secrets.get("ANTHROPIC_API_KEY", "")
    except Exception:
        claude_api = ""

    gemini_status = "success" if gemini_api else "warning"
    claude_status = "success" if claude_api else "warning"

    st.markdown(f"""
    <div style="margin-bottom: 1rem;">
        <span class="status-badge status-{gemini_status}">
            {'Connected' if gemini_api else 'Not set'} Gemini API
        </span>
        <br>
        <span class="status-badge status-{claude_status}">
            {'Connected' if claude_api else 'Not set'} Claude API
        </span>
    </div>
    """, unsafe_allow_html=True)

    st.divider()

    # ë„¤ë¹„ê²Œì´ì…˜
    st.markdown("### ë©”ë‰´")
    page = st.radio(
        "ê¸°ëŠ¥ ì„ íƒ",
        ["ë²•ë ¹ êµ¬ì¡°í™”", "ë²ˆì—­ ì‹¤í–‰", "ìƒì„¸ë³´ê¸°"],
        label_visibility="collapsed"
    )

    st.divider()

    # ë„ì›€ë§
    with st.expander("ì‚¬ìš© ê°€ì´ë“œ"):
        st.markdown("""
        **1ë‹¨ê³„: ë²•ë ¹ êµ¬ì¡°í™”**
        - PDF/XML íŒŒì¼ì—ì„œ ì¡°ë¬¸ ìë™ ì¶”ì¶œ

        **2ë‹¨ê³„: ë²ˆì—­ ì‹¤í–‰**
        - Gemini / Claude ì´ì¤‘ ë²ˆì—­
        - í•œêµ­ë²• ìœ ì‚¬ ì¡°ë¬¸ ë§¤ì¹­

        **3ë‹¨ê³„: ìƒì„¸ë³´ê¸°**
        - ë²ˆì—­ ë¹„êµ ë¶„ì„ ë° ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
        """)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# í˜ì´ì§€ 1: ë²•ë ¹ êµ¬ì¡°í™” (PDF â†’ êµ¬ì¡°í™” ì—‘ì…€)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
if page == "ë²•ë ¹ êµ¬ì¡°í™”":
    st.markdown("""
    <div class="section-header">
        <h3>ë²•ë ¹ êµ¬ì¡°í™”</h3>
    </div>
    """, unsafe_allow_html=True)

    st.markdown("""
    <div class="info-card">
        <p style="margin: 0; color: #64748b;">
            ë²•ë ¹ PDF/XML/HTML íŒŒì¼ì„ ìë™ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ í¸/ì¥/ì ˆ/ì¡°/í•­/í˜¸ ë‹¨ìœ„ë¡œ êµ¬ì¡°í™”í•©ë‹ˆë‹¤.
            êµ¬ì¡°í™”ëœ ë°ì´í„°ëŠ” Excel íŒŒì¼ë¡œ ì €ì¥ë˜ì–´ ë²ˆì—­ ì‘ì—…ì— í™œìš©ë©ë‹ˆë‹¤.
        </p>
    </div>
    """, unsafe_allow_html=True)

    # Step 1: êµ­ê°€ ì„ íƒ
    struct_country = st.selectbox(
        "ğŸ“ êµ­ê°€ ì„ íƒ",
        list(COUNTRY_MAP.keys()),
        key="struct_country",
        help="ë¨¼ì € êµ­ê°€ë¥¼ ì„ íƒí•˜ì„¸ìš”"
    )

    # Step 2: êµ­ê°€ì— ë”°ë¼ ì…ë ¥ ë°©ì‹ í‘œì‹œ
    if struct_country == "ì¼ë³¸":
        # ì¼ë³¸ì€ íŒŒì¼ ì—…ë¡œë“œë§Œ ì§€ì›
        st.info("ğŸ’¡ ì¼ë³¸ ë²•ë ¹ì€ ë‹¤ìš´ë¡œë“œí•œ HTML íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”")

        uploaded_file = st.file_uploader(
            "ì¼ë³¸ ë²•ë ¹ HTML íŒŒì¼ ì—…ë¡œë“œ",
            type=['html'],
            help="e-Gov ë²•ë ¹æ¤œç´¢ì—ì„œ ë‹¤ìš´ë¡œë“œí•œ HTML íŒŒì¼",
            key="japan_html_upload"
        )

        input_method = "íŒŒì¼ ì—…ë¡œë“œ"
        html_url = None
        struct_pdf_selected = None

    elif struct_country == "í”„ë‘ìŠ¤":
        # í”„ë‘ìŠ¤ëŠ” LEGI XML ë””ë ‰í† ë¦¬ ê²½ë¡œ ì…ë ¥
        st.info("ğŸ’¡ í”„ë‘ìŠ¤ ë²•ë ¹ì€ LEGI XML ë””ë ‰í† ë¦¬ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”")

        input_method = st.radio(
            "ğŸ“¥ ì…ë ¥ ë°©ì‹",
            ["ë””ë ‰í† ë¦¬ ê²½ë¡œ ì…ë ¥", "DATA í´ë”ì—ì„œ ì„ íƒ"],
            horizontal=True,
            key="france_input_method"
        )

        if input_method == "ë””ë ‰í† ë¦¬ ê²½ë¡œ ì…ë ¥":
            legi_dir = st.text_input(
                "LEGI XML ë””ë ‰í† ë¦¬ ê²½ë¡œ",
                value="DATA/FRANCE/CPI_only/LEGITEXT000006069414",
                help="article/LEGI/ARTI í´ë”ê°€ í¬í•¨ëœ ë””ë ‰í† ë¦¬ ê²½ë¡œ",
                key="france_legi_dir"
            )
            html_url = legi_dir  # ê²½ë¡œë¥¼ html_url ë³€ìˆ˜ì— ì €ì¥
            uploaded_file = None
            struct_pdf_selected = None
        else:
            # DATA/FRANCE í´ë”ì—ì„œ ì„ íƒ
            france_folder = os.path.join(DATA_DIR, "FRANCE")
            legi_dirs = []
            if os.path.exists(france_folder):
                for root, dirs, files in os.walk(france_folder):
                    # LEGITEXTë¡œ ì‹œì‘í•˜ëŠ” ë””ë ‰í† ë¦¬ ì°¾ê¸°
                    for d in dirs:
                        if d.startswith("LEGITEXT"):
                            full_path = os.path.join(root, d)
                            # article í´ë”ê°€ ìˆëŠ”ì§€ í™•ì¸
                            if os.path.exists(os.path.join(full_path, "article")):
                                rel_path = os.path.relpath(full_path, DATA_DIR)
                                legi_dirs.append(rel_path)

            if not legi_dirs:
                st.warning(f"`{france_folder}/` í´ë”ì— LEGI XML ë””ë ‰í† ë¦¬ë¥¼ ë„£ì–´ì£¼ì„¸ìš”.")

            selected_legi = st.selectbox(
                "LEGI ë””ë ‰í† ë¦¬ ì„ íƒ",
                legi_dirs if legi_dirs else [""],
                disabled=not legi_dirs,
                key="france_legi_select"
            )

            html_url = os.path.join(DATA_DIR, selected_legi) if selected_legi else None
            uploaded_file = None
            struct_pdf_selected = None
    
    elif struct_country in ["ì¤‘êµ­", "ë‰´ì§ˆëœë“œ", "ëŒ€ë§Œ", "ë…ì¼", "ëŸ¬ì‹œì•„"]:
        # HTML URL ì „ìš© (PDF ì§€ì› ì•ˆ í•¨)
        st.info("ğŸ’¡ í•´ë‹¹ êµ­ê°€ëŠ” ê³µì‹ ë²•ë ¹ ì›¹ì‚¬ì´íŠ¸ URLì„ ì…ë ¥í•˜ì„¸ìš”")

        input_method = "HTML URL ì…ë ¥"

        _url_placeholders = {
            "ì¤‘êµ­": "https://www.cnipa.gov.cn/art/2020/11/23/art_97_155167.html",
            "ë‰´ì§ˆëœë“œ": "https://www.legislation.govt.nz/act/public/2013/0068/latest/DLM1419624.html",
            "ëŒ€ë§Œ": "https://law.moj.gov.tw/ENG/LawClass/LawAll.aspx?pcode=J0070007",
            "ë…ì¼": "https://www.gesetze-im-internet.de/patg/BJNR201170936.html",
            "ëŸ¬ì‹œì•„": "https://rospatent.gov.ru/en/documents/grazhdanskiy-kodeks-rossiyskoy-federacii-chast-chetvertaya",
        }
        html_url = st.text_input(
            "ë²•ë ¹ HTML URL",
            placeholder=_url_placeholders.get(struct_country, ""),
            key="html_url"
        )
        uploaded_file = None
        struct_pdf_selected = None

    elif struct_country == "ìœ ëŸ½(EPC)":
        # ìœ ëŸ½ì€ HTML URL ë˜ëŠ” PDF íŒŒì¼
        input_method = st.radio(
            "ğŸ“¥ ì…ë ¥ ë°©ì‹",
            ["HTML URL ì…ë ¥", "íŒŒì¼ ì—…ë¡œë“œ"],
            horizontal=True,
            key="input_method"
        )

        if input_method == "HTML URL ì…ë ¥":
            html_url = st.text_input(
                "ë²•ë ¹ HTML URL",
                placeholder="https://eur-lex.europa.eu/...",
                key="html_url"
            )
            uploaded_file = None
            struct_pdf_selected = None
        else:
            html_url = None
            struct_folder = COUNTRY_MAP[struct_country]
            struct_pdfs = _list_pdfs(struct_folder)

            if not struct_pdfs:
                st.warning(f"`{DATA_DIR}/{struct_folder}/` í´ë”ì— íŒŒì¼ì„ ë„£ì–´ì£¼ì„¸ìš”.")

            struct_pdf_selected = st.selectbox(
                "ë²•ë ¹ íŒŒì¼ ì„ íƒ",
                struct_pdfs,
                format_func=_basename,
                disabled=not struct_pdfs,
                key="struct_pdf",
            )
            uploaded_file = None
    else:
        # ê¸°íƒ€ êµ­ê°€ëŠ” íŒŒì¼ ì—…ë¡œë“œë§Œ
        input_method = "íŒŒì¼ ì—…ë¡œë“œ"
        html_url = None
        uploaded_file = None

        struct_folder = COUNTRY_MAP[struct_country]
        struct_pdfs = _list_pdfs(struct_folder)

        if not struct_pdfs:
            st.warning(f"`{DATA_DIR}/{struct_folder}/` í´ë”ì— PDF ë˜ëŠ” XML íŒŒì¼ì„ ë„£ì–´ì£¼ì„¸ìš”.")

        struct_pdf_selected = st.selectbox(
            "ë²•ë ¹ íŒŒì¼ ì„ íƒ",
            struct_pdfs,
            format_func=_basename,
            disabled=not struct_pdfs,
            key="struct_pdf",
        )

    # ì‹¤í–‰ ë²„íŠ¼
    can_run = False
    if struct_country == "ì¼ë³¸":
        can_run = uploaded_file is not None
    elif struct_country == "í”„ë‘ìŠ¤":
        can_run = html_url is not None and html_url.strip() != ""
    elif input_method == "HTML URL ì…ë ¥" or input_method == "ë””ë ‰í† ë¦¬ ê²½ë¡œ ì…ë ¥":
        can_run = html_url is not None and html_url.strip() != ""
    else:
        can_run = struct_pdf_selected is not None

    struct_run = st.button(
        "ğŸš€ êµ¬ì¡°í™” ì‹¤í–‰",
        type="primary",
        disabled=not can_run,
        key="struct_run",
    )

    if struct_run:
        output_dir = os.path.join(DATA_DIR, "output")
        os.makedirs(output_dir, exist_ok=True)

        with st.status("ë²•ë ¹ êµ¬ì¡°í™” íŒŒì‹± ì¤‘...", expanded=True) as status:
            # ì¼ë³¸ HTML íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬
            if struct_country == "ì¼ë³¸" and uploaded_file:
                st.write(f"ì¼ë³¸ ë²•ë ¹ HTML íŒŒì‹± ì¤‘: {uploaded_file.name}")
                try:
                    # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
                    import tempfile
                    with tempfile.NamedTemporaryFile(delete=False, suffix='.html') as tmp_file:
                        tmp_file.write(uploaded_file.getvalue())
                        tmp_path = tmp_file.name

                    # ì¼ë³¸ íŒŒì„œ ì‚¬ìš©
                    from japan_parser import parse_japan_html_to_dataframe
                    df_structured = parse_japan_html_to_dataframe(tmp_path)

                    st.write(f"{len(df_structured)}ê°œ í•­ëª© ì¶”ì¶œ (ç« /ç¯€/æ¢/é …/è™Ÿ ë‹¨ìœ„)")

                    # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                    os.unlink(tmp_path)

                    # íŒŒì¼ëª… ìƒì„±
                    base_name = os.path.splitext(uploaded_file.name)[0]
                except Exception as e:
                    st.error(f"ì¼ë³¸ ë²•ë ¹ íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
                    import traceback
                    st.error(traceback.format_exc())
                    st.stop()

            # í”„ë‘ìŠ¤ LEGI XML ë””ë ‰í† ë¦¬ ì²˜ë¦¬
            elif struct_country == "í”„ë‘ìŠ¤" and html_url:
                st.write(f"í”„ë‘ìŠ¤ LEGI XML íŒŒì‹± ì¤‘: {html_url}")
                try:
                    from parsers.france import parse_french_legi_xml
                    import pandas as pd

                    # Lì¡°ë¬¸ íŒŒì‹±
                    st.write("ğŸ“– Lì¡°ë¬¸ (Partie lÃ©gislative) íŒŒì‹± ì¤‘...")
                    df_l = parse_french_legi_xml(html_url, "L")
                    l_count = len(df_l)
                    st.write(f"  âœ“ {l_count}ê°œ í–‰ ì¶”ì¶œ")

                    # Rì¡°ë¬¸ íŒŒì‹±
                    st.write("ğŸ“– Rì¡°ë¬¸ (Partie rÃ©glementaire) íŒŒì‹± ì¤‘...")
                    df_r = parse_french_legi_xml(html_url, "R")
                    r_count = len(df_r)
                    st.write(f"  âœ“ {r_count}ê°œ í–‰ ì¶”ì¶œ")

                    # ì „ì²´ í•©ì¹˜ê¸°
                    df_structured = pd.concat([df_l, df_r], ignore_index=True)
                    st.write(f"âœ… ì´ {len(df_structured)}ê°œ í•­ëª© ì¶”ì¶œ (í¸/ì¥/ì ˆ/ì¡°/í•­/í˜¸/ëª© ë‹¨ìœ„)")

                    # íŒŒì¼ëª… ìƒì„±
                    law_name = os.path.basename(html_url)
                    base_name = f"í”„ë‘ìŠ¤_{law_name}"
                except Exception as e:
                    st.error(f"í”„ë‘ìŠ¤ LEGI XML íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
                    import traceback
                    st.error(traceback.format_exc())
                    st.stop()

            # HTML URL ì…ë ¥ ë°©ì‹
            elif input_method == "HTML URL ì…ë ¥":
                st.write(f"HTML íŒŒì‹± ì¤‘: {html_url}")
                try:
                    # êµ­ê°€ë³„ íŒŒì„œ ì„ íƒ
                    if struct_country == "ì¤‘êµ­":
                        df_structured = parse_china_html_to_dataframe(html_url)
                    elif struct_country == "ë‰´ì§ˆëœë“œ":
                        df_structured = parse_nz_html_to_dataframe(html_url)
                    elif struct_country == "ëŒ€ë§Œ":
                        df_structured = parse_taiwan_html_to_dataframe(html_url)
                    elif struct_country == "ë…ì¼":
                        df_structured = parse_germany_html_to_dataframe(html_url)
                    elif struct_country == "ëŸ¬ì‹œì•„":
                        df_structured = parse_russia_html_to_dataframe(html_url)
                    else:
                        df_structured = parse_eu_html_to_dataframe(html_url)

                    st.write(f"{len(df_structured)}ê°œ í•­ëª© ì¶”ì¶œ (ì¡°/í•­/í˜¸ ë‹¨ìœ„)")

                    # íŒŒì¼ëª… ìƒì„± (URLì—ì„œ ì¶”ì¶œ)
                    import hashlib
                    url_hash = hashlib.md5(html_url.encode()).hexdigest()[:8]
                    base_name = f"{struct_country}_HTML_{url_hash}"
                except Exception as e:
                    st.error(f"HTML íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
                    st.stop()

            # íŒŒì¼ ì„ íƒ ë°©ì‹
            elif struct_pdf_selected:
                st.write(f"{_basename(struct_pdf_selected)} ì²˜ë¦¬ ì¤‘...")

                # XML íŒŒì¼ì¸ì§€ PDF íŒŒì¼ì¸ì§€ í™•ì¸
                file_extension = os.path.splitext(struct_pdf_selected)[1].lower()

                if file_extension == '.xml':
                    # XML íŒŒì¼ ì²˜ë¦¬ (ë…ì¼ë²•)
                    from pdf_parser import extract_structured_articles_from_xml
                    st.write("ë…ì¼ ë²•ë ¹ XML íŒŒì‹± ì¤‘...")
                    df_structured = extract_structured_articles_from_xml(
                        struct_pdf_selected,
                        country=struct_country,
                        law_name="íŠ¹í—ˆë²•"  # ê¸°ë³¸ê°’, í•„ìš”ì‹œ UIì—ì„œ ì„ íƒ ê°€ëŠ¥í•˜ë„ë¡ í™•ì¥ ê°€ëŠ¥
                    )
                    st.write(f"{len(df_structured)}ê°œ í•­ëª© ì¶”ì¶œ (ì¡°/í•­ ë‹¨ìœ„)")
                elif file_extension == '.rtf':
                    # RTF íŒŒì¼ ì²˜ë¦¬ (ë¯¸êµ­ë²•)
                    st.write("ë¯¸êµ­ ë²•ë ¹ RTF íŒŒì‹± ì¤‘...")
                    df_structured = extract_structured_articles(struct_pdf_selected)
                    st.write(f"{len(df_structured)}ê°œ í•­ëª© ì¶”ì¶œ (ì¡°/í•­/í˜¸ ë‹¨ìœ„)")
                else:
                    # PDF/RTF íŒŒì¼ ì²˜ë¦¬
                    df_structured = extract_structured_articles(struct_pdf_selected)
                    st.write(f"{len(df_structured)}ê°œ í•­ëª© ì¶”ì¶œ (ì¡°/í•­/í˜¸ ë‹¨ìœ„)")

                # íŒŒì¼ëª… ìƒì„±
                base_name = os.path.splitext(os.path.basename(struct_pdf_selected))[0]
            else:
                st.error("íŒŒì¼ì„ ì„ íƒí•˜ê±°ë‚˜ URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                st.stop()

            # êµ¬ì¡°í™” íŒŒì¼ì€ êµ¬ì¡°í™”ë²•ë¥  í´ë”ì˜ êµ­ê°€ë³„ í•˜ìœ„ í´ë”ì— ì €ì¥
            structured_dir = _safe_join(DATA_DIR, "output", "êµ¬ì¡°í™”ë²•ë¥ ")
            os.makedirs(structured_dir, exist_ok=True)

            # íŒŒì¼ëª… ìƒì„±
            if struct_country == "ì¼ë³¸" and uploaded_file:
                # ì¼ë³¸ ì—…ë¡œë“œ íŒŒì¼ì˜ ê²½ìš°
                base_name_structured = f"êµ¬ì¡°í™”_{struct_country}_{base_name}"
            elif struct_country == "í”„ë‘ìŠ¤":
                # í”„ë‘ìŠ¤ LEGI XMLì˜ ê²½ìš° ì´ë¯¸ base_nameì´ ìƒì„±ë¨
                base_name_structured = f"êµ¬ì¡°í™”_{base_name}"
            elif input_method == "HTML URL ì…ë ¥" or input_method == "ë””ë ‰í† ë¦¬ ê²½ë¡œ ì…ë ¥":
                # HTML URLì˜ ê²½ìš° ì´ë¯¸ base_nameì´ ìƒì„±ë¨
                base_name_structured = f"êµ¬ì¡°í™”_{base_name}"
            else:
                # íŒŒì¼ í™•ì¥ì ì œê±° (.pdf ë˜ëŠ” .xml)
                base_name_no_ext = _basename(struct_pdf_selected).rsplit('.', 1)[0]
                base_name_structured = f"êµ¬ì¡°í™”_{struct_country}_{base_name_no_ext}"

            # êµ­ê°€ë³„ í•˜ìœ„ í´ë” ìƒì„± ë° ì €ì¥
            country = _detect_country_from_filename(base_name_structured)
            if country:
                folder_name = _country_to_folder_name(country)
                country_dir = os.path.join(structured_dir, folder_name)
                os.makedirs(country_dir, exist_ok=True)
                excel_path = os.path.join(country_dir, f"{base_name_structured}.xlsx")
            else:
                # êµ­ê°€ ê°ì§€ ì‹¤íŒ¨ ì‹œ ë£¨íŠ¸ í´ë”ì— ì €ì¥
                excel_path = os.path.join(structured_dir, f"{base_name_structured}.xlsx")

            # ì¡°ë¬¸ë²ˆí˜¸ ì •ê·œí™”: 'Section N' / 'Article N' / 'Rule N' / 'Â§ N' â†’ 'N'
            if 'ì¡°ë¬¸ë²ˆí˜¸' in df_structured.columns:
                df_structured['ì¡°ë¬¸ë²ˆí˜¸'] = df_structured['ì¡°ë¬¸ë²ˆí˜¸'].apply(
                    lambda x: _article_num_display(str(x)) if pd.notna(x) and str(x).strip() not in ('ì „ë¬¸', '') else x
                )

            save_structured_to_excel(df_structured, excel_path)
            st.write(f"ì €ì¥ ì™„ë£Œ: `{excel_path}`")

            status.update(label="êµ¬ì¡°í™” ì™„ë£Œ", state="complete")

        # ë¯¸ë¦¬ë³´ê¸°
        st.subheader("êµ¬ì¡°í™” ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°")
        st.dataframe(df_structured.head(20), use_container_width=True, hide_index=True)

        # Excel ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì¶”ê°€
        import io
        excel_buffer = io.BytesIO()
        with pd.ExcelWriter(excel_buffer, engine="openpyxl") as writer:
            df_structured.to_excel(writer, index=False, sheet_name="ë²•ì¡°ë¬¸")
        excel_data = excel_buffer.getvalue()

        st.download_button(
            label="ğŸ“¥ êµ¬ì¡°í™” Excel ë‹¤ìš´ë¡œë“œ",
            data=excel_data,
            file_name=os.path.basename(excel_path),
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            key="structured_excel_download"
        )

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# í˜ì´ì§€ 2: ë²ˆì—­ ì‹¤í–‰ (êµ¬ì¡°í™” ì—‘ì…€ â†’ ë²ˆì—­ + í•œêµ­ë²• ë§¤ì¹­)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
elif page == "ë²ˆì—­ ì‹¤í–‰":
    st.markdown("""
    <div class="section-header">
        <h3>AI ë²ˆì—­ ë° ë§¤ì¹­</h3>
    </div>
    """, unsafe_allow_html=True)

    st.markdown("""
    <div class="info-card">
        <p style="margin: 0; color: #64748b;">
            êµ¬ì¡°í™”ëœ ë²•ë ¹ì„ Gemini ë° Claude AIë¡œ ì´ì¤‘ ë²ˆì—­í•˜ê³ , í•œêµ­ íŠ¹í—ˆë²•ì˜ ìœ ì‚¬ ì¡°ë¬¸ì„ ìë™ìœ¼ë¡œ ë§¤ì¹­í•©ë‹ˆë‹¤.
            ë²ˆì—­ ê²°ê³¼ëŠ” Excel íŒŒì¼ë¡œ ì €ì¥ë˜ì–´ ìƒì„¸ ë¹„êµê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.
        </p>
    </div>
    """, unsafe_allow_html=True)

    st.markdown("")  # ì—¬ë°±

    # â”€â”€ ì™¸êµ­ë²• êµ¬ì¡°í™” ì—‘ì…€ ì„ íƒ (ë‚˜ë¼ë³„ í•„í„°) â”€â”€
    st.markdown("#### ì™¸êµ­ë²• ì„ íƒ")

    # êµ¬ì¡°í™”ë²•ë¥  í´ë”ì˜ êµ­ê°€ë³„ ì„œë¸Œí´ë”ì—ì„œ íŒŒì¼ ìˆ˜ì§‘
    structured_dir = _safe_join(DATA_DIR, "output", "êµ¬ì¡°í™”ë²•ë¥ ")
    country_files: dict = {}
    if os.path.isdir(structured_dir):
        for entry in sorted(os.listdir(structured_dir)):
            if entry == "í•œêµ­":
                continue
            country_dir = os.path.join(structured_dir, entry)
            if os.path.isdir(country_dir):
                files = sorted(
                    [f for f in glob.glob(os.path.join(country_dir, "*.xlsx"))
                     if not _basename(f).startswith("~$")],
                    key=os.path.getmtime, reverse=True,
                )
                if files:
                    country_files[entry] = files

    countries_with_files = list(country_files.keys())

    if not countries_with_files:
        st.warning(
            f"`{structured_dir}` í´ë”ì— êµ¬ì¡°í™” ì—‘ì…€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\n\n"
            "'ë²•ë ¹ êµ¬ì¡°í™”' íƒ­ì—ì„œ ë¨¼ì € PDFë¥¼ êµ¬ì¡°í™”í•˜ì„¸ìš”."
        )
        foreign_excel_selected = None
    else:
        col_country, col_file = st.columns([1, 2])
        with col_country:
            selected_country = st.selectbox(
                "êµ­ê°€ ì„ íƒ",
                countries_with_files,
                key="trans_country_select",
            )
        files_for_country = country_files.get(selected_country, [])
        with col_file:
            foreign_excel_selected = st.selectbox(
                "êµ¬ì¡°í™” ì—‘ì…€ ì„ íƒ",
                files_for_country,
                format_func=_basename,
                disabled=not files_for_country,
                key="trans_foreign_excel",
            )

    # ì†ŒìŠ¤ ì–¸ì–´ ì„ íƒ
    col_lang, col_service = st.columns(2)
    with col_lang:
        source_lang_option = st.selectbox(
            "ì†ŒìŠ¤ ì–¸ì–´", ["ìë™ ê°ì§€", "ì˜ì–´", "ì¤‘êµ­ì–´"],
            key="trans_source_lang",
            help="íŒŒì¼ëª…ì—ì„œ ìë™ ê°ì§€í•˜ê±°ë‚˜, ìˆ˜ë™ìœ¼ë¡œ ì„ íƒí•˜ì„¸ìš”.",
        )

    # ë²ˆì—­ ì„œë¹„ìŠ¤ ì„ íƒ
    with col_service:
        translation_service = st.selectbox(
            "ë²ˆì—­ ì„œë¹„ìŠ¤",
            ["Gemini + Claude (ì´ì¤‘ ë²ˆì—­)", "Claudeë§Œ", "Geminië§Œ"],
            key="translation_service",
            help="ì‚¬ìš©í•  ë²ˆì—­ ì„œë¹„ìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”. API í‚¤ê°€ ì—†ëŠ” ê²½ìš° í•´ë‹¹ ì„œë¹„ìŠ¤ëŠ” ê±´ë„ˆëœë‹ˆë‹¤.",
        )

    st.divider()

    # â”€â”€ í•œêµ­ë²• ì„ íƒ â”€â”€
    st.markdown("#### í•œêµ­ë²• ì„ íƒ (ë‹¤ì¤‘ ê°€ëŠ¥)")
    st.caption("êµ¬ì¡°í™” ì—‘ì…€ê³¼ PDFë¥¼ í˜¼í•©í•˜ì—¬ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    korea_excels = _list_korea_excels()
    korea_pdfs = _list_pdfs(KOREA_FOLDER)

    col_ke, col_kp = st.columns(2)
    with col_ke:
        korea_excel_selected = st.multiselect(
            "í•œêµ­ë²• êµ¬ì¡°í™” ì—‘ì…€",
            korea_excels, format_func=_basename,
            key="trans_korea_excel",
            help="êµ¬ì¡°í™”ëœ ì—‘ì…€ íŒŒì¼ë¡œ í•œêµ­ë²•ì„ ë¡œë“œí•˜ë©´ ì¡°/í•­/í˜¸ ë‹¨ìœ„ë¡œ ë” ì •í™•í•œ ë§¤ì¹­ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.",
        )
    with col_kp:
        if not korea_pdfs:
            st.warning(f"`{DATA_DIR}/{KOREA_FOLDER}/` í´ë”ì— í•œêµ­ ë²•ë ¹ PDFë¥¼ ë„£ì–´ì£¼ì„¸ìš”.")
        korea_pdf_selected = st.multiselect(
            "í•œêµ­ë²• PDF",
            korea_pdfs, format_func=_basename,
            key="trans_korea_pdf",
        )

    has_korea = bool(korea_excel_selected) or bool(korea_pdf_selected)

    st.divider()

    # í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì˜µì…˜
    test_mode = st.checkbox(
        "í…ŒìŠ¤íŠ¸ ëª¨ë“œ â€” ì²˜ìŒ 20ì¡°ê¹Œì§€ë§Œ ì²˜ë¦¬",
        value=False,
        key="test_mode",
        help="ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì²˜ìŒ 20ê°œ ì¡°ë¬¸ë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤."
    )

    btn_col1, btn_col2, btn_col3 = st.columns(3)
    with btn_col1:
        trans_run = st.button(
            "ë²ˆì—­ ì‹¤í–‰", type="primary",
            disabled=not foreign_excel_selected or not has_korea,
            use_container_width=True, key="trans_run",
        )
    with btn_col2:
        retrans_run = st.button(
            "ì¬ë²ˆì—­ â€” íŠ¹ì • ì¡°ë¬¸",
            disabled=not foreign_excel_selected or not has_korea,
            use_container_width=True, key="retrans_run",
        )
    with btn_col3:
        rematch_run = st.button(
            "ì¬ë§¤ì¹­ â€” ìœ ì‚¬ ì¡°ë¬¸",
            disabled=not foreign_excel_selected or not has_korea,
            use_container_width=True, key="rematch_run",
        )

    # ë²ˆì—­ ì‹¤í–‰ ë²„íŠ¼ í´ë¦­ ì‹œ session stateì— ì €ì¥
    if trans_run:
        st.session_state.translation_started = True
        st.session_state.retranslation_started = False
        st.session_state.rematch_started = False
        # ìƒˆë¡œìš´ ë²ˆì—­ ì‹¤í–‰ ì‹œì‘ - ì„ íƒ state ì´ˆê¸°í™”
        if "proceed_with_choice" in st.session_state:
            del st.session_state.proceed_with_choice
        if "use_existing" in st.session_state:
            del st.session_state.use_existing
        # ì´ì „ ë²ˆì—­ ê²°ê³¼ ë° ì§„í–‰ ìƒíƒœ ì´ˆê¸°í™”
        st.session_state._trans_result = None
        st.session_state._trans_error = None
        st.session_state._trans_done = False
        st.session_state._trans_thread_active = False
        st.session_state._trans_progress = {"current": 0, "total": 0, "text": "ë²ˆì—­ ì¤€ë¹„ ì¤‘..."}
        st.session_state._trans_cancel_event = threading.Event()

    if retrans_run:
        st.session_state.retranslation_started = True
        st.session_state.translation_started = False
        st.session_state.rematch_started = False

    if rematch_run:
        st.session_state.rematch_started = True
        st.session_state.translation_started = False
        st.session_state.retranslation_started = False

    # â”€â”€ ì´ì „ ë²ˆì—­ ê²°ê³¼ í‘œì‹œ (íƒ­ ì´ë™ í›„ ë³µê·€ ì‹œì—ë„ ìœ ì§€) â”€â”€
    if (not st.session_state.get("translation_started")
            and not st.session_state.get("retranslation_started")
            and not st.session_state.get("rematch_started")
            and st.session_state.get("_trans_result")):
        _prev = st.session_state._trans_result
        st.success(f"ë²ˆì—­ ì™„ë£Œ - ì €ì¥ ìœ„ì¹˜: {_prev['xlsx_path']}")
        st.dataframe(_prev["df_display"], use_container_width=True, hide_index=True)
        _c1, _c2 = st.columns(2)
        with _c1:
            st.download_button(
                "Excel ë‹¤ìš´ë¡œë“œ", _prev["excel_data"], f"{_prev['base_name']}.xlsx",
                "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                key="trans_xlsx_dl_prev",
            )
        with _c2:
            if st.button("ìƒˆ ë²ˆì—­ ì‹œì‘ (ê²°ê³¼ ì´ˆê¸°í™”)", key="clear_trans_result"):
                st.session_state._trans_result = None
                st.rerun()

    # ë²ˆì—­ì´ ì‹œì‘ëœ ê²½ìš° ì‹¤í–‰
    if st.session_state.get("translation_started", False) and foreign_excel_selected:

        # â”€â”€ ê¸°ì¡´ ë²ˆì—­ ê²°ê³¼ í™•ì¸ â”€â”€
        # íŒŒì¼ëª…ì—ì„œ êµ­ê°€/ë²•ë ¹ëª… ì¶”ì¶œ
        fname = _basename(foreign_excel_selected).replace(".xlsx", "")

        # íŒŒì¼ëª…ì—ì„œ êµ­ê°€ì™€ ë²•ë ¹ëª… ì¶”ì¶œ: êµ¬ì¡°í™”_êµ­ê°€_ë²•ë ¹ëª…
        parts = fname.split("_", 2)
        if len(parts) >= 3 and parts[0] == "êµ¬ì¡°í™”":
            trans_country = parts[1]
            trans_law_name = parts[2]
        elif len(parts) >= 2 and parts[0] == "êµ¬ì¡°í™”":
            trans_country = parts[1]
            trans_law_name = parts[1]
        else:
            # ë¹„í‘œì¤€ í˜•ì‹: íŒŒì¼ëª… ì „ì²´ ì‚¬ìš©
            trans_country = fname
            trans_law_name = fname

        # í…ŒìŠ¤íŠ¸ ëª¨ë“œì¼ ê²½ìš° íŒŒì¼ëª…ì— í‘œì‹œ
        test_suffix = "_í…ŒìŠ¤íŠ¸" if test_mode else ""
        base_name = f"ë²ˆì—­ë¹„êµ_{trans_country}_{trans_law_name}{test_suffix}"

        # ë²ˆì—­ ìŠ¤ë ˆë“œ ì‹¤í–‰ ì¤‘/ì™„ë£Œ ì‹œ ê¸°ì¡´ íŒŒì¼ UI ê±´ë„ˆëœ€
        existing_csv = None
        if not (st.session_state.get("_trans_thread_active") or st.session_state.get("_trans_done")):
            for search_dir in [_safe_join(DATA_DIR, "output"), PROJECT_DIR]:
                for ext in [".csv", ".xlsx"]:
                    candidate = _safe_join(search_dir, f"{base_name}{ext}")
                    if os.path.exists(candidate):
                        existing_csv = candidate
                        break
                if existing_csv:
                    break

        if existing_csv:
            st.warning("ê¸°ì¡´ ë²ˆì—­ ê²°ê³¼ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.")

            df_existing = None
            if existing_csv.endswith((".xlsx", ".xls")):
                try:
                    df_existing = pd.read_excel(existing_csv)
                except Exception:
                    pass
            else:
                for enc in ["utf-8-sig", "utf-8"]:
                    try:
                        df_existing = pd.read_csv(existing_csv, encoding=enc)
                        break
                    except (UnicodeDecodeError, UnicodeError):
                        continue

            if df_existing is not None:
                st.info(f"íŒŒì¼: `{_basename(existing_csv)}`")

                info_col1, info_col2, info_col3 = st.columns(3)
                with info_col1:
                    st.metric("ì´ ì¡°ë¬¸ ìˆ˜", len(df_existing))
                with info_col2:
                    if "ë§¤ì¹­ ì ìˆ˜" in df_existing.columns:
                        scores = pd.to_numeric(df_existing["ë§¤ì¹­ ì ìˆ˜"], errors="coerce")
                        avg_score = scores.mean()
                        st.metric("í‰ê·  ë§¤ì¹­ ì ìˆ˜", f"{avg_score:.3f}" if pd.notna(avg_score) else "-")
                with info_col3:
                    if "ë§¤ì¹­ ì´ìœ " in df_existing.columns:
                        reason_count = df_existing["ë§¤ì¹­ ì´ìœ "].notna().sum()
                        st.metric("ë§¤ì¹­ ì´ìœ  ì œê³µ", f"{reason_count}ê±´")

                st.subheader("ê¸°ì¡´ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 5ê°œ ì¡°ë¬¸)")
                preview_df = df_existing.head(5).copy()
                for col in ["ì›ë¬¸", "Gemini ë²ˆì—­", "Claude ë²ˆì—­"]:
                    if col in preview_df.columns:
                        preview_df[col] = preview_df[col].apply(
                            lambda x: str(x)[:100] + "..." if pd.notna(x) and len(str(x)) > 100 else x
                        )
                st.dataframe(preview_df, use_container_width=True, hide_index=True)

                st.divider()

                st.subheader("ë²ˆì—­ ì‹¤í–‰ ë°©ì‹ ì„ íƒ")
                choice = st.radio(
                    "ì–´ë–»ê²Œ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ?",
                    [
                        "ê¸°ì¡´ ë²ˆì—­ ê²°ê³¼ ì‚¬ìš© (ë¹ ë¦„, ë¹„ìš© ì ˆê°)",
                        "ìƒˆë¡œ ë²ˆì—­ ì‹¤í–‰ (API í˜¸ì¶œ, ì‹œê°„ ì†Œìš”)"
                    ],
                    key="use_existing_choice",
                    help="ê¸°ì¡´ ê²°ê³¼ë¥¼ ì‚¬ìš©í•˜ë©´ API í˜¸ì¶œ ì—†ì´ ì¦‰ì‹œ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                )
                use_existing = choice.startswith("ê¸°ì¡´")

                st.divider()
                col_btn1, col_btn2, col_btn3 = st.columns([1, 1, 2])
                with col_btn1:
                    if st.button("ì„ íƒ í™•ì •", type="primary", use_container_width=True, key="confirm_choice_btn"):
                        st.session_state.proceed_with_choice = True
                        st.session_state.use_existing = use_existing
                with col_btn2:
                    if st.button("ì·¨ì†Œ", use_container_width=True, key="cancel_choice_btn"):
                        if "proceed_with_choice" in st.session_state:
                            del st.session_state.proceed_with_choice
                        if "use_existing" in st.session_state:
                            del st.session_state.use_existing
                        st.info("ë¶„ì„ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                        st.stop()

                if not st.session_state.get("proceed_with_choice", False):
                    st.info("ìœ„ì—ì„œ ì˜µì…˜ì„ ì„ íƒí•˜ê³  'ì„ íƒ í™•ì •' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
                    st.stop()

                # session_stateì—ì„œ ì„ íƒ ê°’ ê°€ì ¸ì˜¤ê¸°
                use_existing = st.session_state.get("use_existing", True)

                if use_existing:
                    st.success(f"ê¸°ì¡´ ê²°ê³¼ ë¡œë“œ ì™„ë£Œ: {len(df_existing)}ê±´")
                    if "ì¡°ë¬¸" in df_existing.columns:
                        df_existing = df_existing[df_existing["ì¡°ë¬¸"] != "ì „ë¬¸"]
                    st.dataframe(df_existing, use_container_width=True, hide_index=True, height=400)
                    st.info("'ìƒì„¸ë³´ê¸°' íƒ­ì—ì„œ ìƒì„¸ ë‚´ìš©ì„ í™•ì¸í•˜ì„¸ìš”.")
                    st.stop()

        # ê¸°ì¡´ ê²°ê³¼ë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²½ìš° ìƒˆë¡œ ë²ˆì—­ ì‹¤í–‰
        if not st.session_state.get("use_existing", False):
            # íŒŒì¼ ë¡œë“œ + ìŠ¤ë ˆë“œ ì‹œì‘ì€ ì²˜ìŒ í•œ ë²ˆë§Œ (í´ë§ rerun ì‹œ ê±´ë„ˆëœ€)
            if not st.session_state.get("_trans_thread_active") and not st.session_state.get("_trans_done"):
                # â”€â”€ 1) ì™¸êµ­ë²• ì—‘ì…€ ë¡œë“œ â”€â”€
                with st.status("ì™¸êµ­ë²• êµ¬ì¡°í™” ì—‘ì…€ ë¡œë“œ ì¤‘...", expanded=True) as status:
                    try:
                        df_foreign = pd.read_excel(foreign_excel_selected)
                        st.write(f"{_basename(foreign_excel_selected)} ë¡œë“œ: {len(df_foreign)}ê±´")
                    except Exception as e:
                        st.error(f"ì—‘ì…€ ì½ê¸° ì‹¤íŒ¨: {e}")
                        st.stop()

                    required_cols = ["ì¡°ë¬¸ë²ˆí˜¸", "ì›ë¬¸"]
                    missing_cols = [c for c in required_cols if c not in df_foreign.columns]
                    if missing_cols:
                        st.error(f"í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing_cols}")
                        st.stop()

                    for col in ["í¸", "ì¥", "ì ˆ", "ì¡°ë¬¸ì œëª©", "í•­", "í˜¸", "ëª©", "ì„¸ëª©"]:
                        if col in df_foreign.columns:
                            df_foreign[col] = df_foreign[col].fillna("").astype(str)
                        else:
                            df_foreign[col] = ""

                    foreign_articles = []
                    for _, row in df_foreign.iterrows():
                        article_id = f"{row['ì¡°ë¬¸ë²ˆí˜¸']}"
                        if row['í•­']:
                            article_id += f"-{row['í•­']}"
                        if row['í˜¸']:
                            article_id += f"-{row['í˜¸']}"
                        text = str(row["ì›ë¬¸"]) if pd.notna(row["ì›ë¬¸"]) else ""
                        if not text.strip():
                            continue
                        foreign_articles.append({
                            "id": article_id, "text": text,
                            "í¸": str(row.get("í¸", "")) if pd.notna(row.get("í¸")) else "",
                            "ì¥": str(row.get("ì¥", "")) if pd.notna(row.get("ì¥")) else "",
                            "ì ˆ": str(row.get("ì ˆ", "")) if pd.notna(row.get("ì ˆ")) else "",
                            "ì¡°ë¬¸ë²ˆí˜¸": str(row["ì¡°ë¬¸ë²ˆí˜¸"]) if pd.notna(row["ì¡°ë¬¸ë²ˆí˜¸"]) else "",
                            "ì¡°ë¬¸ì œëª©": str(row.get("ì¡°ë¬¸ì œëª©", "")) if pd.notna(row.get("ì¡°ë¬¸ì œëª©")) else "",
                            "í•­": str(row.get("í•­", "")) if pd.notna(row.get("í•­")) else "",
                            "í˜¸": str(row.get("í˜¸", "")) if pd.notna(row.get("í˜¸")) else "",
                            "ëª©": str(row.get("ëª©", "")) if pd.notna(row.get("ëª©")) else "",
                            "ì„¸ëª©": str(row.get("ì„¸ëª©", "")) if pd.notna(row.get("ì„¸ëª©")) else "",
                        })

                    if test_mode:
                        unique_articles = []
                        seen_article_nums = set()
                        for art in foreign_articles:
                            art_num = art.get("ì¡°ë¬¸ë²ˆí˜¸", "")
                            if art_num not in seen_article_nums:
                                seen_article_nums.add(art_num)
                            if len(seen_article_nums) <= 20:
                                unique_articles.append(art)
                            else:
                                break
                        foreign_articles = unique_articles
                        st.info(f"í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ì²˜ìŒ 20ê°œ ì¡°ë¬¸ë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤ (ì´ {len(foreign_articles)}ê°œ í•­ëª©)")

                    if source_lang_option == "ì˜ì–´":
                        source_lang = "english"
                    elif source_lang_option == "ì¤‘êµ­ì–´":
                        source_lang = "chinese"
                    else:
                        source_lang = _detect_lang(foreign_excel_selected)
                    st.write(f"ì†ŒìŠ¤ ì–¸ì–´: {source_lang}")
                    status.update(label="ì™¸êµ­ë²• ë¡œë“œ ì™„ë£Œ", state="complete")

                # â”€â”€ 2) í•œêµ­ë²• ë¡œë“œ (AI ë§¤ì¹­ìš©) â”€â”€
                with st.status("í•œêµ­ ë²•ë ¹ ë¡œë“œ ì¤‘...", expanded=True) as status:
                    all_korea_articles = []
                    for excel_path in korea_excel_selected:
                        try:
                            df_korea = pd.read_excel(excel_path)
                            source_name = _basename(excel_path)
                            korea_by_article = {}
                            for _, row in df_korea.iterrows():
                                article_num = row.get('ì¡°ë¬¸ë²ˆí˜¸', '')
                                if pd.notna(article_num) and str(article_num).strip():
                                    article_num = str(article_num)
                                    if article_num not in korea_by_article:
                                        korea_by_article[article_num] = {
                                            'rows': [],
                                            'title': str(row.get('ì¡°ë¬¸ì œëª©', '')).strip() if pd.notna(row.get('ì¡°ë¬¸ì œëª©')) else ""
                                        }
                                    text = str(row.get("ì›ë¬¸", "")).strip()
                                    if text:
                                        korea_by_article[article_num]['rows'].append(text)
                            for article_num, data in korea_by_article.items():
                                combined_text = "\n".join(data['rows'])
                                all_korea_articles.append({
                                    "id": article_num, "text": combined_text,
                                    "source": source_name, "title": data['title'],
                                })
                            st.write(f"{source_name}: {len(korea_by_article)}ê°œ ì¡°ë¬¸")
                        except Exception as e:
                            st.warning(f"ì—‘ì…€ ì½ê¸° ì‹¤íŒ¨ ({_basename(excel_path)}): {e}")

                    for kp in korea_pdf_selected:
                        k_text = parse_pdf(kp)
                        k_articles = split_articles(k_text, lang="korean")
                        for a in k_articles:
                            a["source"] = _basename(kp)
                        all_korea_articles.extend(k_articles)
                        st.write(f"{_basename(kp)}: {len(k_articles)}ê°œ ì¡°ë¬¸")

                    if not all_korea_articles:
                        st.error("í•œêµ­ë²• ì¡°ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤. ì—‘ì…€ ë˜ëŠ” PDFë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
                        st.stop()

                    korea_index = {"articles": all_korea_articles}
                    st.write(f"í•œêµ­ë²• ì´ {len(all_korea_articles)}ê°œ ì¡°ë¬¸ ë¡œë“œ ì™„ë£Œ")
                    status.update(label="í•œêµ­ ë²•ë ¹ ë¡œë“œ ì™„ë£Œ", state="complete")

                # â”€â”€ 3) ë²ˆì—­ ì‹¤í–‰ (ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ) â”€â”€
                use_gemini = "Gemini" in translation_service
                use_claude = "Claude" in translation_service

                _cancel_ev = st.session_state.get("_trans_cancel_event", threading.Event())

                # ìŠ¤ë ˆë“œì™€ ê³µìœ í•  ì¼ë°˜ Python dict (st.session_state ì§ì ‘ ì ‘ê·¼ ëŒ€ì‹  ì‚¬ìš©)
                _shared = {
                    "progress": {"current": 0, "total": 0, "text": "ë²ˆì—­ ì¤€ë¹„ ì¤‘..."},
                    "result": None,
                    "error": None,
                    "done": False,
                }
                st.session_state._trans_shared = _shared

                # ìŠ¤ë ˆë“œì— ë„˜ê¸¸ ì…ë ¥ ë°ì´í„° (ì¼ë°˜ ë³€ìˆ˜ë¡œ í´ë¡œì € ìº¡ì²˜)
                _inp = {
                    "foreign_articles": foreign_articles,
                    "all_korea_articles": all_korea_articles,
                    "korea_index": korea_index,
                    "source_lang": source_lang,
                    "base_name": base_name,
                    "use_gemini": use_gemini,
                    "use_claude": use_claude,
                    "trans_country": trans_country,
                    "foreign_excel_selected": foreign_excel_selected,
                }

                def _translation_worker(_inp=_inp, _shared=_shared, _cev=_cancel_ev):
                    """ë°±ê·¸ë¼ìš´ë“œ ë²ˆì—­ ìŠ¤ë ˆë“œ - st.session_state ì§ì ‘ ì ‘ê·¼ ê¸ˆì§€"""
                    try:
                        # ì§„í–‰ë¥  ì½œë°± (ì·¨ì†Œ ì²´í¬ í¬í•¨)
                        def _prog(cur, tot):
                            _shared["progress"] = {
                                "current": cur, "total": tot,
                                "text": f"ë²ˆì—­ ì¤‘... ({cur}/{tot})"
                            }
                            if _cev and _cev.is_set():
                                raise StopIteration("ì·¨ì†Œë¨")

                        _translated = translate_batch(
                            _inp["foreign_articles"],
                            source_lang=_inp["source_lang"],
                            progress_callback=_prog,
                            group_by_article=True,
                            use_gemini=_inp["use_gemini"],
                            use_claude=_inp["use_claude"],
                            cancel_event=_cev,
                        )

                        if _cev and _cev.is_set():
                            _shared["error"] = "ì‚¬ìš©ìê°€ ë²ˆì—­ì„ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤."
                            return

                        _shared["progress"] = {"current": 0, "total": 0, "text": "í•œêµ­ë²• ë§¤ì¹­ ì¤‘..."}

                        # ê´€ë ¨ í•œêµ­ë²• ì„ íƒ
                        _korea_law_sources = sorted(set(
                            a.get("source", "") for a in _inp["all_korea_articles"] if a.get("source")
                        ))
                        _sample_text = ""
                        for item in _translated:
                            if item["id"] != "ì „ë¬¸" and not item["id"].endswith("(ì‚­ì œ)"):
                                _sample_text = item.get("gemini", "") or item.get("claude", "")
                                break
                        _relevant_sources = select_relevant_korean_laws(
                            _basename(_inp["foreign_excel_selected"]), _sample_text, _korea_law_sources,
                        )

                        if _cev and _cev.is_set():
                            _shared["error"] = "ì‚¬ìš©ìê°€ ë²ˆì—­ì„ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤."
                            return

                        # ì¡°ë¬¸ ë‹¨ìœ„ ê·¸ë£¹í™”
                        from collections import defaultdict
                        _article_groups = defaultdict(list)
                        for item in _translated:
                            _art_num = item.get("ì¡°ë¬¸ë²ˆí˜¸", item["id"])
                            _article_groups[_art_num].append(item)

                        # ì¼ê´„ ë§¤ì¹­ ì¤€ë¹„
                        _batch_articles = []
                        for _art_num, _group in _article_groups.items():
                            if _art_num != "ì „ë¬¸" and not _art_num.endswith("(ì‚­ì œ)"):
                                _fi = _group[0]
                                _batch_articles.append({
                                    'id': _art_num,
                                    'text': str(_fi.get("original", "")),
                                    'ì¡°ë¬¸ì œëª©': _fi.get("ì¡°ë¬¸ì œëª©", ""),
                                    'translated': str(_fi.get("gemini", "")) or str(_fi.get("claude", "")),
                                })

                        _shared["progress"] = {"current": 0, "total": 0, "text": "í•œêµ­ë²• AI ë§¤ì¹­ ì¤‘..."}
                        _batch_results = find_similar_korean_batch(
                            _batch_articles, _inp["korea_index"],
                            relevant_law_sources=_relevant_sources,
                        )

                        # ë§¤ì¹­ ê²°ê³¼ í• ë‹¹
                        for _art_num, _group in _article_groups.items():
                            if _art_num == "ì „ë¬¸" or _art_num.endswith("(ì‚­ì œ)"):
                                for item in _group:
                                    item["similar_korean"] = []
                            else:
                                _skey = str(_art_num)
                                for _pfx in ["Article ", "Section ", "Rule ", "ç¬¬"]:
                                    if _skey.startswith(_pfx):
                                        _skey = _skey[len(_pfx):]
                                        break
                                _skey = _skey.rstrip("æ¢")
                                _matches = _batch_results.get(_skey, []) or _batch_results.get(str(_art_num), [])
                                for item in _group:
                                    item["similar_korean"] = _matches

                        # ê²°ê³¼ DataFrame êµ¬ì„±
                        _rows_full = []
                        _rows_display = []
                        for _art_num, _group in _article_groups.items():
                            _fi = _group[0]
                            _best_match = _best_score = _best_kt = _best_reason = ""
                            if _fi.get("similar_korean"):
                                _top = _fi["similar_korean"][0]
                                _lname = _korean_law_name(_top.get("source", ""))
                                _kid = _top['korean_id']
                                if not _kid.startswith("ì œ"):
                                    _kid = f"ì œ{_kid}ì¡°"
                                _best_match = f"{_lname} {_kid}"
                                _best_score = f"{_top['score']:.3f}"
                                _best_kt = _top.get("korean_text", "")
                                _best_reason = _top.get("ai_reason", "")

                            _combined_orig = str(_fi.get("original", ""))
                            _combined_gem = str(_fi.get("gemini", ""))
                            _combined_cla = str(_fi.get("claude", ""))
                            _row = {"êµ­ê°€": _inp["trans_country"]}
                            for _k in ["í¸", "ì¥", "ì ˆ", "ì¡°ë¬¸ë²ˆí˜¸", "ì¡°ë¬¸ì œëª©"]:
                                _row[_k] = _fi.get(_k, "")

                            _rows_full.append({
                                **_row, "ì›ë¬¸": _combined_orig,
                                "Gemini ë²ˆì—­": _combined_gem, "Claude ë²ˆì—­": _combined_cla,
                                "ìœ ì‚¬ í•œêµ­ë²•": _best_match, "ë§¤ì¹­ ì ìˆ˜": _best_score,
                                "í•œêµ­ë²• ì¡°ë¬¸ ë‚´ìš©": _best_kt, "ë§¤ì¹­ ì´ìœ ": _best_reason,
                            })
                            _rows_display.append({
                                **_row,
                                "ì›ë¬¸": _combined_orig[:200] + ("..." if len(_combined_orig) > 200 else ""),
                                "Gemini ë²ˆì—­": _combined_gem[:200] + ("..." if len(_combined_gem) > 200 else ""),
                                "Claude ë²ˆì—­": _combined_cla[:200] + ("..." if len(_combined_cla) > 200 else ""),
                                "ìœ ì‚¬ í•œêµ­ë²•": _best_match, "ë§¤ì¹­ ì´ìœ ": _best_reason,
                            })

                        _df_full = pd.DataFrame(_rows_full)
                        _df_display = pd.DataFrame(_rows_display)

                        # Excel ì €ì¥
                        _trans_dir = _safe_join(DATA_DIR, "output", "ë²ˆì—­ë¹„êµê²°ê³¼")
                        os.makedirs(_trans_dir, exist_ok=True)
                        _fparts = _inp["foreign_excel_selected"].replace("\\", "/").split("/")
                        _cfolder = None
                        if "êµ¬ì¡°í™”ë²•ë¥ " in _fparts:
                            _ci = _fparts.index("êµ¬ì¡°í™”ë²•ë¥ ")
                            if _ci + 1 < len(_fparts):
                                _cfolder = _fparts[_ci + 1]
                        if _cfolder and _cfolder in COUNTRY_MAP:
                            _cdir = os.path.join(_trans_dir, _cfolder)
                            os.makedirs(_cdir, exist_ok=True)
                            _xlsx_path = os.path.join(_cdir, f"{_inp['base_name']}.xlsx")
                        else:
                            _xlsx_path = os.path.join(_trans_dir, f"{_inp['base_name']}.xlsx")

                        _buf = io.BytesIO()
                        with pd.ExcelWriter(_buf, engine="openpyxl") as _ew:
                            _df_full.to_excel(_ew, index=False, sheet_name="ë²ˆì—­ê²°ê³¼")
                            _ws = _ew.sheets["ë²ˆì—­ê²°ê³¼"]
                            for _row_cells in _ws.iter_rows():
                                for _cell in _row_cells:
                                    _cell.alignment = Alignment(wrap_text=True, vertical='top')
                        _excel_data = _buf.getvalue()
                        with open(_xlsx_path, "wb") as _f:
                            _f.write(_excel_data)

                        _shared["result"] = {
                            "df_display": _df_display,
                            "excel_data": _excel_data,
                            "base_name": _inp["base_name"],
                            "xlsx_path": _xlsx_path,
                        }

                    except StopIteration:
                        _shared["error"] = "ì‚¬ìš©ìê°€ ë²ˆì—­ì„ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤."
                    except Exception as _e:
                        _shared["error"] = str(_e)
                    finally:
                        _shared["done"] = True

                _t = threading.Thread(target=_translation_worker, daemon=True)
                _t.start()
                st.session_state._trans_thread_active = True
                # íŒŒì¼ ë¡œë“œ í™”ë©´ì„ ì§€ìš°ê³  ê¹¨ë—í•œ ì§„í–‰ í™”ë©´ìœ¼ë¡œ ì „í™˜
                st.rerun()

            # â”€â”€ ì§„í–‰ ì¤‘: í”„ë¡œê·¸ë ˆìŠ¤ë°” + ì·¨ì†Œ ë²„íŠ¼ í‘œì‹œ â”€â”€
            _shared = st.session_state.get("_trans_shared", {})
            if not _shared.get("done"):
                _prog = _shared.get("progress", {})
                _cur = _prog.get("current", 0)
                _tot = max(_prog.get("total", 1), 1)
                st.subheader("ë²ˆì—­ ì§„í–‰")
                st.progress(_cur / _tot, text=_prog.get("text", "ë²ˆì—­ ì¤‘..."))

                if st.button("ë²ˆì—­ ì·¨ì†Œ", key="cancel_trans_btn", type="secondary"):
                    _cev2 = st.session_state.get("_trans_cancel_event")
                    if _cev2:
                        _cev2.set()
                    st.warning("ì·¨ì†Œ ìš”ì²­ì´ ì „ì†¡ë˜ì—ˆìŠµë‹ˆë‹¤. í˜„ì¬ ì¡°ë¬¸ ì²˜ë¦¬ ì™„ë£Œ í›„ ì¤‘ë‹¨ë©ë‹ˆë‹¤.")
                    time.sleep(0.5)
                    st.rerun()

                # ì™„ë£Œë  ë•Œê¹Œì§€ í´ë§
                time.sleep(0.5)
                st.rerun()
                st.stop()

            # â”€â”€ ì™„ë£Œ: shared â†’ session_stateë¡œ ë³µì‚¬ í›„ rerun â”€â”€
            st.session_state.translation_started = False
            st.session_state._trans_done = True
            st.session_state._trans_thread_active = False
            if _shared.get("result"):
                st.session_state._trans_result = _shared["result"]
                st.rerun()  # ì´ì „ ê²°ê³¼ í‘œì‹œ ë¸”ë¡(ìƒë‹¨)ìœ¼ë¡œ ì „í™˜
            if _shared.get("error"):
                st.error(_shared["error"])
            st.stop()

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ì¬ë²ˆì—­ ëª¨ë“œ
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    elif st.session_state.get("retranslation_started", False) and foreign_excel_selected:

        # â”€â”€ ê¸°ì¡´ ë²ˆì—­ê²°ê³¼ íŒŒì¼ ì°¾ê¸° â”€â”€
        fname = _basename(foreign_excel_selected).replace(".xlsx", "")

        # íŒŒì¼ëª…ì—ì„œ êµ­ê°€ì™€ ë²•ë ¹ëª… ì¶”ì¶œ: êµ¬ì¡°í™”_êµ­ê°€_ë²•ë ¹ëª…
        parts = fname.split("_", 2)
        if len(parts) >= 3 and parts[0] == "êµ¬ì¡°í™”":
            trans_country = parts[1]
            trans_law_name = parts[2]
        elif len(parts) >= 2 and parts[0] == "êµ¬ì¡°í™”":
            trans_country = parts[1]
            trans_law_name = parts[1]
        else:
            trans_country = fname
            trans_law_name = fname

        # ê¸°ì¡´ ë²ˆì—­ê²°ê³¼ íŒŒì¼ ê²€ìƒ‰ (í…ŒìŠ¤íŠ¸ í¬í•¨)
        existing_result = None
        for test_suffix in ["", "_í…ŒìŠ¤íŠ¸"]:
            base_name = f"ë²ˆì—­ë¹„êµ_{trans_country}_{trans_law_name}{test_suffix}"
            for search_dir in [
                _safe_join(DATA_DIR, "output", "ë²ˆì—­ë¹„êµê²°ê³¼"),
                _safe_join(DATA_DIR, "output"),
                PROJECT_DIR,
            ]:
                for ext in [".xlsx", ".csv"]:
                    candidate = _safe_join(search_dir, f"{base_name}{ext}")
                    if os.path.exists(candidate):
                        existing_result = candidate
                        break
                if existing_result:
                    break
            if existing_result:
                break

        if not existing_result:
            st.error("ê¸°ì¡´ ë²ˆì—­ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € 'ë²ˆì—­ ì‹¤í–‰'ì„ í•´ì£¼ì„¸ìš”.")
            st.stop()

        # â”€â”€ êµ¬ì¡°í™” ì—‘ì…€ ë° ê¸°ì¡´ ë²ˆì—­ê²°ê³¼ ë¡œë“œ â”€â”€
        try:
            df_foreign = pd.read_excel(foreign_excel_selected)
        except Exception as e:
            st.error(f"êµ¬ì¡°í™” ì—‘ì…€ ì½ê¸° ì‹¤íŒ¨: {e}")
            st.stop()

        try:
            if existing_result.endswith((".xlsx", ".xls")):
                df_existing = pd.read_excel(existing_result)
            else:
                df_existing = pd.read_csv(existing_result, encoding="utf-8-sig")
        except Exception as e:
            st.error(f"ê¸°ì¡´ ë²ˆì—­ê²°ê³¼ ì½ê¸° ì‹¤íŒ¨: {e}")
            st.stop()

        st.info(f"êµ¬ì¡°í™” ì—‘ì…€: `{_basename(foreign_excel_selected)}`\n\n"
                f"ê¸°ì¡´ ë²ˆì—­ê²°ê³¼: `{_basename(existing_result)}`")

        # â”€â”€ ì¡°ë¬¸ ëª©ë¡ í‘œì‹œ (ì²´í¬ë°•ìŠ¤) â”€â”€
        st.subheader("ì¬ë²ˆì—­í•  ì¡°ë¬¸ ì„ íƒ")
        st.caption("êµ¬ì¡°í™” ì—‘ì…€ì—ì„œ ìˆ˜ì •í•œ ì¡°ë¬¸ì„ ì²´í¬í•˜ì„¸ìš”. ì„ íƒí•œ ì¡°ë¬¸ë§Œ ì¬ë²ˆì—­ + ì¬ë§¤ì¹­ë©ë‹ˆë‹¤.")

        # ì¡°ë¬¸ë²ˆí˜¸ë³„ë¡œ ê·¸ë£¹í™” (ì¤‘ë³µ ì¡°ë¬¸ë²ˆí˜¸ í•˜ë‚˜ë¡œ í‘œì‹œ)
        article_nums_seen = []
        article_info = {}
        for _, row in df_foreign.iterrows():
            art_num = str(row.get("ì¡°ë¬¸ë²ˆí˜¸", ""))
            if not art_num or art_num in article_info:
                continue
            art_title = str(row.get("ì¡°ë¬¸ì œëª©", "")) if pd.notna(row.get("ì¡°ë¬¸ì œëª©")) else ""
            article_nums_seen.append(art_num)
            article_info[art_num] = art_title

        # ì „ì²´ ì„ íƒ / í•´ì œ
        def _retrans_toggle_all():
            val = st.session_state.retrans_select_all
            for a_num in article_info:
                st.session_state[f"retrans_chk_{a_num}"] = val

        st.checkbox("ì „ì²´ ì„ íƒ", value=False, key="retrans_select_all", on_change=_retrans_toggle_all)

        selected_articles = []
        cols_per_row = 3
        article_list = list(article_info.items())

        for i in range(0, len(article_list), cols_per_row):
            cols = st.columns(cols_per_row)
            for j, col in enumerate(cols):
                idx = i + j
                if idx >= len(article_list):
                    break
                art_num, art_title = article_list[idx]
                label = _article_num_display(art_num)
                if art_title:
                    label += f" ({art_title})"
                with col:
                    if st.checkbox(label, key=f"retrans_chk_{art_num}"):
                        selected_articles.append(art_num)

        if not selected_articles:
            st.warning("ì¬ë²ˆì—­í•  ì¡°ë¬¸ì„ ì„ íƒí•˜ì„¸ìš”.")
            st.stop()

        st.success(f"ì„ íƒëœ ì¡°ë¬¸: {len(selected_articles)}ê°œ")

        # â”€â”€ ì¬ë²ˆì—­ ì‹¤í–‰ ë²„íŠ¼ â”€â”€
        retrans_execute = st.button(
            f"ì„ íƒí•œ {len(selected_articles)}ê°œ ì¡°ë¬¸ ì¬ë²ˆì—­ + ì¬ë§¤ì¹­ ì‹¤í–‰",
            type="primary", use_container_width=True, key="retrans_execute",
        )

        if retrans_execute:
            # â”€â”€ 1) ì„ íƒí•œ ì¡°ë¬¸ë§Œ êµ¬ì¡°í™” ì—‘ì…€ì—ì„œ ì¶”ì¶œ â”€â”€
            with st.status("ì„ íƒí•œ ì¡°ë¬¸ ë¡œë“œ ì¤‘...", expanded=True) as status:
                # NaN ì±„ìš°ê¸°
                for col in ["í¸", "ì¥", "ì ˆ", "ì¡°ë¬¸ì œëª©", "í•­", "í˜¸", "ëª©", "ì„¸ëª©"]:
                    if col in df_foreign.columns:
                        df_foreign[col] = df_foreign[col].fillna("").astype(str)
                    else:
                        df_foreign[col] = ""

                retrans_articles = []
                for _, row in df_foreign.iterrows():
                    art_num = str(row.get("ì¡°ë¬¸ë²ˆí˜¸", ""))
                    if art_num not in selected_articles:
                        continue

                    article_id = f"{row['ì¡°ë¬¸ë²ˆí˜¸']}"
                    if row['í•­']:
                        article_id += f"-{row['í•­']}"
                    if row['í˜¸']:
                        article_id += f"-{row['í˜¸']}"

                    text = str(row["ì›ë¬¸"]) if pd.notna(row["ì›ë¬¸"]) else ""
                    if not text.strip():
                        continue

                    retrans_articles.append({
                        "id": article_id,
                        "text": text,
                        "í¸": str(row.get("í¸", "")) if pd.notna(row.get("í¸")) else "",
                        "ì¥": str(row.get("ì¥", "")) if pd.notna(row.get("ì¥")) else "",
                        "ì ˆ": str(row.get("ì ˆ", "")) if pd.notna(row.get("ì ˆ")) else "",
                        "ì¡°ë¬¸ë²ˆí˜¸": str(row["ì¡°ë¬¸ë²ˆí˜¸"]) if pd.notna(row["ì¡°ë¬¸ë²ˆí˜¸"]) else "",
                        "ì¡°ë¬¸ì œëª©": str(row.get("ì¡°ë¬¸ì œëª©", "")) if pd.notna(row.get("ì¡°ë¬¸ì œëª©")) else "",
                        "í•­": str(row.get("í•­", "")) if pd.notna(row.get("í•­")) else "",
                        "í˜¸": str(row.get("í˜¸", "")) if pd.notna(row.get("í˜¸")) else "",
                        "ëª©": str(row.get("ëª©", "")) if pd.notna(row.get("ëª©")) else "",
                        "ì„¸ëª©": str(row.get("ì„¸ëª©", "")) if pd.notna(row.get("ì„¸ëª©")) else "",
                    })

                # ì†ŒìŠ¤ ì–¸ì–´ ê²°ì •
                if source_lang_option == "ì˜ì–´":
                    source_lang = "english"
                elif source_lang_option == "ì¤‘êµ­ì–´":
                    source_lang = "chinese"
                else:
                    source_lang = _detect_lang(foreign_excel_selected)

                st.write(f"{len(retrans_articles)}ê°œ í•­ëª© ë¡œë“œ (ì†ŒìŠ¤ ì–¸ì–´: {source_lang})")
                status.update(label="ì¡°ë¬¸ ë¡œë“œ ì™„ë£Œ", state="complete")

            # â”€â”€ 2) í•œêµ­ë²• ë¡œë“œ â”€â”€
            with st.status("í•œêµ­ ë²•ë ¹ ë¡œë“œ ì¤‘...", expanded=True) as status:
                all_korea_articles = []

                for excel_path in korea_excel_selected:
                    try:
                        df_korea = pd.read_excel(excel_path)
                        source_name = _basename(excel_path)

                        korea_by_article = {}
                        for _, row in df_korea.iterrows():
                            article_num = row.get('ì¡°ë¬¸ë²ˆí˜¸', '')
                            if pd.notna(article_num) and str(article_num).strip():
                                article_num = str(article_num)
                                if article_num not in korea_by_article:
                                    korea_by_article[article_num] = {
                                        'rows': [],
                                        'title': str(row.get('ì¡°ë¬¸ì œëª©', '')).strip() if pd.notna(row.get('ì¡°ë¬¸ì œëª©')) else ""
                                    }
                                text = str(row.get("ì›ë¬¸", "")).strip()
                                if text:
                                    korea_by_article[article_num]['rows'].append(text)

                        for article_num, data in korea_by_article.items():
                            combined_text = "\n".join(data['rows'])
                            all_korea_articles.append({
                                "id": article_num,
                                "text": combined_text,
                                "source": source_name,
                                "title": data['title'],
                            })

                        st.write(f"{source_name}: {len(korea_by_article)}ê°œ ì¡°ë¬¸")
                    except Exception as e:
                        st.warning(f"ì—‘ì…€ ì½ê¸° ì‹¤íŒ¨ ({_basename(excel_path)}): {e}")

                for kp in korea_pdf_selected:
                    k_text = parse_pdf(kp)
                    k_articles = split_articles(k_text, lang="korean")
                    for a in k_articles:
                        a["source"] = _basename(kp)
                    all_korea_articles.extend(k_articles)
                    st.write(f"{_basename(kp)}: {len(k_articles)}ê°œ ì¡°ë¬¸")

                if not all_korea_articles:
                    st.error("í•œêµ­ë²• ì¡°ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")
                    st.stop()

                korea_index = {"articles": all_korea_articles}
                st.write(f"í•œêµ­ë²• ì´ {len(all_korea_articles)}ê°œ ì¡°ë¬¸ ë¡œë“œ ì™„ë£Œ")
                status.update(label="í•œêµ­ ë²•ë ¹ ë¡œë“œ ì™„ë£Œ", state="complete")

            # â”€â”€ 3) ì„ íƒí•œ ì¡°ë¬¸ë§Œ ì¬ë²ˆì—­ â”€â”€
            st.subheader("ì¬ë²ˆì—­ ì§„í–‰")
            progress_bar = st.progress(0, text="ì¬ë²ˆì—­ ì¤€ë¹„ ì¤‘...")

            def _update_progress(current, total):
                progress_bar.progress(current / total, text=f"ì¬ë²ˆì—­ ì¤‘... ({current}/{total})")

            use_gemini = "Gemini" in translation_service
            use_claude = "Claude" in translation_service

            translated = translate_batch(
                retrans_articles,
                source_lang=source_lang,
                progress_callback=_update_progress,
                group_by_article=True,
                use_gemini=use_gemini,
                use_claude=use_claude,
            )
            progress_bar.progress(1.0, text="ì¬ë²ˆì—­ ì™„ë£Œ!")

            # â”€â”€ 4) ì„ íƒí•œ ì¡°ë¬¸ë§Œ ì¬ë§¤ì¹­ â”€â”€
            st.subheader("í•œêµ­ë²• ì¬ë§¤ì¹­")

            with st.status("ê´€ë ¨ í•œêµ­ë²• ì„ íƒ ì¤‘...", expanded=True) as status:
                korea_law_sources = sorted(set(
                    a.get("source", "") for a in all_korea_articles if a.get("source")
                ))
                sample_text = ""
                for item in translated:
                    if item["id"] != "ì „ë¬¸" and not item["id"].endswith("(ì‚­ì œ)"):
                        sample_text = item.get("gemini", "") or item.get("claude", "")
                        break

                relevant_sources = select_relevant_korean_laws(
                    _basename(foreign_excel_selected), sample_text, korea_law_sources,
                )
                for src in relevant_sources:
                    st.write(f"ê´€ë ¨ í•œêµ­ë²•: {_korean_law_name(src)}")
                status.update(label=f"ê´€ë ¨ í•œêµ­ë²• {len(relevant_sources)}ê°œ ì„ íƒ ì™„ë£Œ", state="complete")

            from collections import defaultdict
            article_groups = defaultdict(list)
            for item in translated:
                article_num = item.get("ì¡°ë¬¸ë²ˆí˜¸", item["id"])
                article_groups[article_num].append(item)

            match_progress = st.progress(0, text="í•œêµ­ë²• ì¡°ë¬¸ ì¬ë§¤ì¹­ ì¤‘...")

            batch_articles = []
            for article_num, group in article_groups.items():
                if article_num != "ì „ë¬¸" and not article_num.endswith("(ì‚­ì œ)"):
                    first_item = group[0]
                    batch_articles.append({
                        'id': article_num,
                        'text': str(first_item.get("original", "")),
                        'ì¡°ë¬¸ì œëª©': first_item.get("ì¡°ë¬¸ì œëª©", ""),
                        'translated': str(first_item.get("gemini", "")) or str(first_item.get("claude", ""))
                    })

            match_progress.progress(0.5, text="í•œêµ­ë²• ì¡°ë¬¸ ì¬ë§¤ì¹­ ì¤‘... (AI ì²˜ë¦¬ ì¤‘)")
            batch_results = find_similar_korean_batch(
                batch_articles, korea_index, relevant_law_sources=relevant_sources
            )

            for article_num, group in article_groups.items():
                if article_num == "ì „ë¬¸" or article_num.endswith("(ì‚­ì œ)"):
                    for item in group:
                        item["similar_korean"] = []
                else:
                    search_key = str(article_num)
                    for prefix in ["Article ", "Section ", "Rule ", "ç¬¬"]:
                        if search_key.startswith(prefix):
                            search_key = search_key[len(prefix):]
                            break
                    search_key = search_key.rstrip("æ¢")
                    matches = batch_results.get(search_key, [])
                    if not matches:
                        matches = batch_results.get(str(article_num), [])
                    for item in group:
                        item["similar_korean"] = matches

            match_progress.progress(1.0, text="ì¬ë§¤ì¹­ ì™„ë£Œ!")

            # â”€â”€ 5) ê¸°ì¡´ ë²ˆì—­ê²°ê³¼ Excel ì—…ë°ì´íŠ¸ â”€â”€
            st.subheader("ê²°ê³¼ ì—…ë°ì´íŠ¸")

            # ì¬ë²ˆì—­ëœ ì¡°ë¬¸ìœ¼ë¡œ ìƒˆ í–‰ ìƒì„±
            new_rows = {}
            for article_num, group in article_groups.items():
                first_item = group[0]

                best_match = ""
                best_score = ""
                best_korean_text = ""
                best_reason = ""
                if first_item.get("similar_korean"):
                    top = first_item["similar_korean"][0]
                    law_name = _korean_law_name(top.get("source", ""))
                    korean_id = top['korean_id']
                    if not korean_id.startswith("ì œ"):
                        korean_id = f"ì œ{korean_id}ì¡°"
                    best_match = f"{law_name} {korean_id}"
                    best_score = f"{top['score']:.3f}"
                    best_korean_text = top.get("korean_text", "")
                    best_reason = top.get("ai_reason", "")

                combined_original = str(first_item.get("original", ""))
                combined_gemini = str(first_item.get("gemini", ""))
                combined_claude = str(first_item.get("claude", ""))

                new_rows[str(article_num)] = {
                    "êµ­ê°€": trans_country,
                    "í¸": first_item.get("í¸", ""),
                    "ì¥": first_item.get("ì¥", ""),
                    "ì ˆ": first_item.get("ì ˆ", ""),
                    "ì¡°ë¬¸ë²ˆí˜¸": first_item.get("ì¡°ë¬¸ë²ˆí˜¸", ""),
                    "ì¡°ë¬¸ì œëª©": first_item.get("ì¡°ë¬¸ì œëª©", ""),
                    "ì›ë¬¸": combined_original,
                    "Gemini ë²ˆì—­": combined_gemini,
                    "Claude ë²ˆì—­": combined_claude,
                    "ìœ ì‚¬ í•œêµ­ë²•": best_match,
                    "ë§¤ì¹­ ì ìˆ˜": best_score,
                    "í•œêµ­ë²• ì¡°ë¬¸ ë‚´ìš©": best_korean_text,
                    "ë§¤ì¹­ ì´ìœ ": best_reason,
                }

            # ê¸°ì¡´ DataFrameì—ì„œ í•´ë‹¹ ì¡°ë¬¸ í–‰ êµì²´
            updated_count = 0
            for idx, row in df_existing.iterrows():
                art_num = str(row.get("ì¡°ë¬¸ë²ˆí˜¸", ""))
                if art_num in new_rows:
                    for col, val in new_rows[art_num].items():
                        if col in df_existing.columns:
                            df_existing.at[idx, col] = val
                    updated_count += 1

            # ê¸°ì¡´ íŒŒì¼ì— ë®ì–´ì“°ê¸° ì €ì¥
            excel_buffer = io.BytesIO()
            with pd.ExcelWriter(excel_buffer, engine="openpyxl") as writer:
                df_existing.to_excel(writer, index=False, sheet_name="ë²ˆì—­ê²°ê³¼")

                # ì…€ í¬ë§·íŒ…: ì¤„ë°”ê¿ˆ í‘œì‹œ
                worksheet = writer.sheets["ë²ˆì—­ê²°ê³¼"]
                for row in worksheet.iter_rows():
                    for cell in row:
                        cell.alignment = Alignment(wrap_text=True, vertical='top')

            excel_data = excel_buffer.getvalue()

            with open(existing_result, "wb") as f:
                f.write(excel_data)

            st.success(
                f"ì¬ë²ˆì—­ ì™„ë£Œ â€” {updated_count}ê°œ ì¡°ë¬¸ì´ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.\n\n"
                f"ì €ì¥: `{_basename(existing_result)}`"
            )

            # ì—…ë°ì´íŠ¸ëœ ì¡°ë¬¸ ë¯¸ë¦¬ë³´ê¸°
            st.subheader("ì—…ë°ì´íŠ¸ëœ ì¡°ë¬¸")
            updated_df = df_existing[df_existing["ì¡°ë¬¸ë²ˆí˜¸"].astype(str).isin(selected_articles)]
            if not updated_df.empty:
                display_cols = ["ì¡°ë¬¸ë²ˆí˜¸", "ì¡°ë¬¸ì œëª©", "ì›ë¬¸", "Gemini ë²ˆì—­", "Claude ë²ˆì—­", "ìœ ì‚¬ í•œêµ­ë²•"]
                display_cols = [c for c in display_cols if c in updated_df.columns]
                preview = updated_df[display_cols].copy()
                for col in ["ì›ë¬¸", "Gemini ë²ˆì—­", "Claude ë²ˆì—­"]:
                    if col in preview.columns:
                        preview[col] = preview[col].apply(
                            lambda x: str(x)[:150] + "..." if pd.notna(x) and len(str(x)) > 150 else x
                        )
                st.dataframe(preview, use_container_width=True, hide_index=True)

            st.download_button(
                "ì—…ë°ì´íŠ¸ëœ Excel ë‹¤ìš´ë¡œë“œ", excel_data,
                _basename(existing_result),
                "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                key="retrans_dl",
            )

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ì¬ë§¤ì¹­ ëª¨ë“œ (ë²ˆì—­ì€ ìœ ì§€, ìœ ì‚¬ ì¡°ë¬¸ ë§¤ì¹­ë§Œ ë‹¤ì‹œ)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    elif st.session_state.get("rematch_started", False) and foreign_excel_selected:

        # â”€â”€ ê¸°ì¡´ ë²ˆì—­ê²°ê³¼ íŒŒì¼ ì°¾ê¸° â”€â”€
        fname = _basename(foreign_excel_selected).replace(".xlsx", "")

        # íŒŒì¼ëª…ì—ì„œ êµ­ê°€ì™€ ë²•ë ¹ëª… ì¶”ì¶œ: êµ¬ì¡°í™”_êµ­ê°€_ë²•ë ¹ëª…
        parts = fname.split("_", 2)
        if len(parts) >= 3 and parts[0] == "êµ¬ì¡°í™”":
            trans_country = parts[1]
            trans_law_name = parts[2]
        elif len(parts) >= 2 and parts[0] == "êµ¬ì¡°í™”":
            trans_country = parts[1]
            trans_law_name = parts[1]
        else:
            trans_country = fname
            trans_law_name = fname

        existing_result = None
        for test_suffix in ["", "_í…ŒìŠ¤íŠ¸"]:
            base_name = f"ë²ˆì—­ë¹„êµ_{trans_country}_{trans_law_name}{test_suffix}"
            for search_dir in [
                _safe_join(DATA_DIR, "output", "ë²ˆì—­ë¹„êµê²°ê³¼"),
                _safe_join(DATA_DIR, "output"),
                PROJECT_DIR,
            ]:
                for ext in [".xlsx", ".csv"]:
                    candidate = _safe_join(search_dir, f"{base_name}{ext}")
                    if os.path.exists(candidate):
                        existing_result = candidate
                        break
                if existing_result:
                    break
            if existing_result:
                break

        if not existing_result:
            st.error("ê¸°ì¡´ ë²ˆì—­ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € 'ë²ˆì—­ ì‹¤í–‰'ì„ í•´ì£¼ì„¸ìš”.")
            st.stop()

        # â”€â”€ ê¸°ì¡´ ë²ˆì—­ê²°ê³¼ ë¡œë“œ â”€â”€
        try:
            if existing_result.endswith((".xlsx", ".xls")):
                df_existing = pd.read_excel(existing_result)
            else:
                df_existing = pd.read_csv(existing_result, encoding="utf-8-sig")
        except Exception as e:
            st.error(f"ê¸°ì¡´ ë²ˆì—­ê²°ê³¼ ì½ê¸° ì‹¤íŒ¨: {e}")
            st.stop()

        st.info(f"ê¸°ì¡´ ë²ˆì—­ê²°ê³¼: `{_basename(existing_result)}`")

        # â”€â”€ ì¡°ë¬¸ ëª©ë¡ í‘œì‹œ (ì²´í¬ë°•ìŠ¤) â”€â”€
        st.subheader("ì¬ë§¤ì¹­í•  ì¡°ë¬¸ ì„ íƒ")
        st.caption("ìœ ì‚¬ í•œêµ­ë²• ë§¤ì¹­ì„ ë‹¤ì‹œ ì‹¤í–‰í•  ì¡°ë¬¸ì„ ì²´í¬í•˜ì„¸ìš”. ë²ˆì—­ì€ ê·¸ëŒ€ë¡œ ìœ ì§€ë©ë‹ˆë‹¤.")

        # ì¡°ë¬¸ë²ˆí˜¸ ëª©ë¡ ì¶”ì¶œ
        article_info = {}
        if "ì¡°ë¬¸ë²ˆí˜¸" in df_existing.columns:
            for _, row in df_existing.iterrows():
                art_num = str(row.get("ì¡°ë¬¸ë²ˆí˜¸", ""))
                if not art_num or art_num in article_info:
                    continue
                art_title = str(row.get("ì¡°ë¬¸ì œëª©", "")) if pd.notna(row.get("ì¡°ë¬¸ì œëª©")) else ""
                article_info[art_num] = art_title

        if not article_info:
            st.error("ë²ˆì—­ê²°ê³¼ì—ì„œ ì¡°ë¬¸ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            st.stop()

        def _rematch_toggle_all():
            val = st.session_state.rematch_select_all
            for a_num in article_info:
                st.session_state[f"rematch_chk_{a_num}"] = val

        st.checkbox("ì „ì²´ ì„ íƒ", value=False, key="rematch_select_all", on_change=_rematch_toggle_all)

        selected_articles = []
        cols_per_row = 3
        article_list = list(article_info.items())

        for i in range(0, len(article_list), cols_per_row):
            cols = st.columns(cols_per_row)
            for j, col in enumerate(cols):
                idx = i + j
                if idx >= len(article_list):
                    break
                art_num, art_title = article_list[idx]
                label = _article_num_display(art_num)
                if art_title:
                    label += f" ({art_title})"
                with col:
                    if st.checkbox(label, key=f"rematch_chk_{art_num}"):
                        selected_articles.append(art_num)

        if not selected_articles:
            st.warning("ì¬ë§¤ì¹­í•  ì¡°ë¬¸ì„ ì„ íƒí•˜ì„¸ìš”.")
            st.stop()

        st.success(f"ì„ íƒëœ ì¡°ë¬¸: {len(selected_articles)}ê°œ")

        rematch_execute = st.button(
            f"ì„ íƒí•œ {len(selected_articles)}ê°œ ì¡°ë¬¸ ì¬ë§¤ì¹­ ì‹¤í–‰",
            type="primary", use_container_width=True, key="rematch_execute",
        )

        if rematch_execute:
            # â”€â”€ 1) í•œêµ­ë²• ë¡œë“œ â”€â”€
            with st.status("í•œêµ­ ë²•ë ¹ ë¡œë“œ ì¤‘...", expanded=True) as status:
                all_korea_articles = []

                for excel_path in korea_excel_selected:
                    try:
                        df_korea = pd.read_excel(excel_path)
                        source_name = _basename(excel_path)

                        korea_by_article = {}
                        for _, row in df_korea.iterrows():
                            article_num = row.get('ì¡°ë¬¸ë²ˆí˜¸', '')
                            if pd.notna(article_num) and str(article_num).strip():
                                article_num = str(article_num)
                                if article_num not in korea_by_article:
                                    korea_by_article[article_num] = {
                                        'rows': [],
                                        'title': str(row.get('ì¡°ë¬¸ì œëª©', '')).strip() if pd.notna(row.get('ì¡°ë¬¸ì œëª©')) else ""
                                    }
                                text = str(row.get("ì›ë¬¸", "")).strip()
                                if text:
                                    korea_by_article[article_num]['rows'].append(text)

                        for article_num, data in korea_by_article.items():
                            combined_text = "\n".join(data['rows'])
                            all_korea_articles.append({
                                "id": article_num,
                                "text": combined_text,
                                "source": source_name,
                                "title": data['title'],
                            })

                        st.write(f"{source_name}: {len(korea_by_article)}ê°œ ì¡°ë¬¸")
                    except Exception as e:
                        st.warning(f"ì—‘ì…€ ì½ê¸° ì‹¤íŒ¨ ({_basename(excel_path)}): {e}")

                for kp in korea_pdf_selected:
                    k_text = parse_pdf(kp)
                    k_articles = split_articles(k_text, lang="korean")
                    for a in k_articles:
                        a["source"] = _basename(kp)
                    all_korea_articles.extend(k_articles)
                    st.write(f"{_basename(kp)}: {len(k_articles)}ê°œ ì¡°ë¬¸")

                if not all_korea_articles:
                    st.error("í•œêµ­ë²• ì¡°ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")
                    st.stop()

                korea_index = {"articles": all_korea_articles}
                st.write(f"í•œêµ­ë²• ì´ {len(all_korea_articles)}ê°œ ì¡°ë¬¸ ë¡œë“œ ì™„ë£Œ")
                status.update(label="í•œêµ­ ë²•ë ¹ ë¡œë“œ ì™„ë£Œ", state="complete")

            # â”€â”€ 2) ì„ íƒí•œ ì¡°ë¬¸ì˜ ë²ˆì—­ë¬¸ìœ¼ë¡œ ì¬ë§¤ì¹­ â”€â”€
            st.subheader("ìœ ì‚¬ ì¡°ë¬¸ ì¬ë§¤ì¹­")

            with st.status("ê´€ë ¨ í•œêµ­ë²• ì„ íƒ ì¤‘...", expanded=True) as status:
                korea_law_sources = sorted(set(
                    a.get("source", "") for a in all_korea_articles if a.get("source")
                ))

                # ê¸°ì¡´ ë²ˆì—­ë¬¸ì—ì„œ ìƒ˜í”Œ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
                sample_text = ""
                for _, row in df_existing.iterrows():
                    art_num = str(row.get("ì¡°ë¬¸ë²ˆí˜¸", ""))
                    if art_num in selected_articles:
                        sample_text = str(row.get("Gemini ë²ˆì—­", "")) or str(row.get("Claude ë²ˆì—­", ""))
                        if sample_text:
                            break

                relevant_sources = select_relevant_korean_laws(
                    _basename(foreign_excel_selected), sample_text, korea_law_sources,
                )
                for src in relevant_sources:
                    st.write(f"ê´€ë ¨ í•œêµ­ë²•: {_korean_law_name(src)}")
                status.update(label=f"ê´€ë ¨ í•œêµ­ë²• {len(relevant_sources)}ê°œ ì„ íƒ ì™„ë£Œ", state="complete")

            # ì„ íƒí•œ ì¡°ë¬¸ë§Œ ë§¤ì¹­ ëŒ€ìƒìœ¼ë¡œ êµ¬ì„±
            batch_articles = []
            for _, row in df_existing.iterrows():
                art_num = str(row.get("ì¡°ë¬¸ë²ˆí˜¸", ""))
                if art_num not in selected_articles:
                    continue
                # ì´ë¯¸ ì²˜ë¦¬í•œ ì¡°ë¬¸ë²ˆí˜¸ëŠ” ìŠ¤í‚µ (ì¤‘ë³µ ë°©ì§€)
                if any(b['id'] == art_num for b in batch_articles):
                    continue

                batch_articles.append({
                    'id': art_num,
                    'text': str(row.get("ì›ë¬¸", "")) if pd.notna(row.get("ì›ë¬¸")) else "",
                    'ì¡°ë¬¸ì œëª©': str(row.get("ì¡°ë¬¸ì œëª©", "")) if pd.notna(row.get("ì¡°ë¬¸ì œëª©")) else "",
                    'translated': str(row.get("Gemini ë²ˆì—­", "")) or str(row.get("Claude ë²ˆì—­", ""))
                })

            match_progress = st.progress(0, text="í•œêµ­ë²• ì¡°ë¬¸ ì¬ë§¤ì¹­ ì¤‘...")
            match_progress.progress(0.5, text="í•œêµ­ë²• ì¡°ë¬¸ ì¬ë§¤ì¹­ ì¤‘... (AI ì²˜ë¦¬ ì¤‘)")

            batch_results = find_similar_korean_batch(
                batch_articles, korea_index, relevant_law_sources=relevant_sources
            )

            match_progress.progress(1.0, text="ì¬ë§¤ì¹­ ì™„ë£Œ!")

            # â”€â”€ 3) ê¸°ì¡´ ë²ˆì—­ê²°ê³¼ Excel ì—…ë°ì´íŠ¸ (ë§¤ì¹­ ì»¬ëŸ¼ë§Œ) â”€â”€
            st.subheader("ê²°ê³¼ ì—…ë°ì´íŠ¸")

            updated_count = 0
            for idx, row in df_existing.iterrows():
                art_num = str(row.get("ì¡°ë¬¸ë²ˆí˜¸", ""))
                if art_num not in selected_articles:
                    continue

                # ë§¤ì¹­ ê²°ê³¼ ì°¾ê¸°
                search_key = art_num
                for prefix in ["Article ", "Section ", "Rule ", "ç¬¬"]:
                    if search_key.startswith(prefix):
                        search_key = search_key[len(prefix):]
                        break
                search_key = search_key.rstrip("æ¢")

                matches = batch_results.get(search_key, [])
                if not matches:
                    matches = batch_results.get(art_num, [])

                if matches:
                    top = matches[0]
                    law_name = _korean_law_name(top.get("source", ""))
                    korean_id = top['korean_id']
                    if not korean_id.startswith("ì œ"):
                        korean_id = f"ì œ{korean_id}ì¡°"

                    if "ìœ ì‚¬ í•œêµ­ë²•" in df_existing.columns:
                        df_existing.at[idx, "ìœ ì‚¬ í•œêµ­ë²•"] = f"{law_name} {korean_id}"
                    if "ë§¤ì¹­ ì ìˆ˜" in df_existing.columns:
                        df_existing.at[idx, "ë§¤ì¹­ ì ìˆ˜"] = f"{top['score']:.3f}"
                    if "í•œêµ­ë²• ì¡°ë¬¸ ë‚´ìš©" in df_existing.columns:
                        df_existing.at[idx, "í•œêµ­ë²• ì¡°ë¬¸ ë‚´ìš©"] = top.get("korean_text", "")
                    if "ë§¤ì¹­ ì´ìœ " in df_existing.columns:
                        df_existing.at[idx, "ë§¤ì¹­ ì´ìœ "] = top.get("ai_reason", "")
                else:
                    if "ìœ ì‚¬ í•œêµ­ë²•" in df_existing.columns:
                        df_existing.at[idx, "ìœ ì‚¬ í•œêµ­ë²•"] = ""
                    if "ë§¤ì¹­ ì ìˆ˜" in df_existing.columns:
                        df_existing.at[idx, "ë§¤ì¹­ ì ìˆ˜"] = ""
                    if "í•œêµ­ë²• ì¡°ë¬¸ ë‚´ìš©" in df_existing.columns:
                        df_existing.at[idx, "í•œêµ­ë²• ì¡°ë¬¸ ë‚´ìš©"] = ""
                    if "ë§¤ì¹­ ì´ìœ " in df_existing.columns:
                        df_existing.at[idx, "ë§¤ì¹­ ì´ìœ "] = ""

                updated_count += 1

            # ì €ì¥
            excel_buffer = io.BytesIO()
            with pd.ExcelWriter(excel_buffer, engine="openpyxl") as writer:
                df_existing.to_excel(writer, index=False, sheet_name="ë²ˆì—­ê²°ê³¼")

                # ì…€ í¬ë§·íŒ…: ì¤„ë°”ê¿ˆ í‘œì‹œ
                worksheet = writer.sheets["ë²ˆì—­ê²°ê³¼"]
                for row in worksheet.iter_rows():
                    for cell in row:
                        cell.alignment = Alignment(wrap_text=True, vertical='top')

            excel_data = excel_buffer.getvalue()

            with open(existing_result, "wb") as f:
                f.write(excel_data)

            st.success(
                f"ì¬ë§¤ì¹­ ì™„ë£Œ â€” {updated_count}ê°œ ì¡°ë¬¸ì˜ ìœ ì‚¬ í•œêµ­ë²• ë§¤ì¹­ì´ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.\n\n"
                f"ì €ì¥: `{_basename(existing_result)}`"
            )

            # ì—…ë°ì´íŠ¸ëœ ì¡°ë¬¸ ë¯¸ë¦¬ë³´ê¸°
            st.subheader("ì—…ë°ì´íŠ¸ëœ ë§¤ì¹­ ê²°ê³¼")
            updated_df = df_existing[df_existing["ì¡°ë¬¸ë²ˆí˜¸"].astype(str).isin(selected_articles)]
            if not updated_df.empty:
                display_cols = ["ì¡°ë¬¸ë²ˆí˜¸", "ì¡°ë¬¸ì œëª©", "ìœ ì‚¬ í•œêµ­ë²•", "ë§¤ì¹­ ì ìˆ˜", "ë§¤ì¹­ ì´ìœ "]
                display_cols = [c for c in display_cols if c in updated_df.columns]
                st.dataframe(updated_df[display_cols], use_container_width=True, hide_index=True)

            st.download_button(
                "ì—…ë°ì´íŠ¸ëœ Excel ë‹¤ìš´ë¡œë“œ", excel_data,
                _basename(existing_result),
                "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                key="rematch_dl",
            )

    elif not trans_run:
        pass

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# í˜ì´ì§€ 3: ë²ˆì—­ê²°ê³¼ ìƒì„¸ë³´ê¸°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
else:  # page == "ìƒì„¸ë³´ê¸°"
    st.markdown("""
    <div class="section-header">
        <h3>ë²ˆì—­ ê²°ê³¼ ìƒì„¸ë³´ê¸°</h3>
    </div>
    """, unsafe_allow_html=True)

    st.markdown("""
    <div class="info-card">
        <p style="margin: 0; color: #64748b;">
            ë²ˆì—­ëœ ë²•ë ¹ ì¡°ë¬¸ì„ ì›ë¬¸, Gemini ë²ˆì—­, Claude ë²ˆì—­, í•œêµ­ë²• ë§¤ì¹­ ì •ë³´ì™€ í•¨ê»˜ ë¹„êµ ë¶„ì„í•©ë‹ˆë‹¤.
            ì „ì²´ë³´ê¸° ë˜ëŠ” ì¡°ë¬¸ë³„ ìƒì„¸ë³´ê¸° ëª¨ë“œë¥¼ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        </p>
    </div>
    """, unsafe_allow_html=True)

    st.markdown("")  # ì—¬ë°±

    result_files = _list_result_files()

    # êµ­ê°€ ëª©ë¡: ì‹¤ì œ í´ë” ê¸°ì¤€ (íŒŒì¼ ìœ ë¬´ ë¬´ê´€, ìƒˆ í´ë” ì¶”ê°€ ì‹œ ìë™ ë°˜ì˜)
    _translation_dir = _safe_join(DATA_DIR, "output", "ë²ˆì—­ë¹„êµê²°ê³¼")
    _all_countries = []
    if os.path.isdir(_translation_dir):
        _all_countries = sorted([
            d for d in os.listdir(_translation_dir)
            if os.path.isdir(os.path.join(_translation_dir, d)) and d != "í•œêµ­"
        ])

    # íŒŒì¼ì„ êµ­ê°€ë³„ë¡œ ë¶„ë¥˜
    _detail_country_files: dict = {c: [] for c in _all_countries}
    for _f in result_files:
        _rel = _f.replace("\\", "/")
        _parts = _rel.split("/")
        if "ë²ˆì—­ë¹„êµê²°ê³¼" in _parts:
            _idx = _parts.index("ë²ˆì—­ë¹„êµê²°ê³¼")
            _c = _parts[_idx + 1] if _idx + 1 < len(_parts) - 1 else "(ê¸°íƒ€)"
        else:
            _c = "(ê¸°íƒ€)"
        if _c in _detail_country_files:
            _detail_country_files[_c].append(_f)
        else:
            _detail_country_files.setdefault(_c, []).append(_f)

    if not _all_countries:
        st.warning(
            "ì¡°íšŒí•  ë²ˆì—­ ê²°ê³¼ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\n\n"
            "'ë²ˆì—­ ì‹¤í–‰' íƒ­ì—ì„œ ë¨¼ì € ë²ˆì—­ì„ ì§„í–‰í•´ì£¼ì„¸ìš”."
        )
    else:
        _col_c, _col_f = st.columns([1, 2])
        with _col_c:
            _sel_country = st.selectbox("êµ­ê°€ ì„ íƒ", _all_countries, key="detail_country_select")
        _files_for_detail = _detail_country_files.get(_sel_country, [])
        with _col_f:
            selected_file = st.selectbox(
                "ê²°ê³¼ íŒŒì¼ ì„ íƒ",
                _files_for_detail if _files_for_detail else ["(íŒŒì¼ ì—†ìŒ)"],
                format_func=_basename,
                disabled=not _files_for_detail,
                key="csv_viewer_select",
            )
        selected_file = selected_file if _files_for_detail else None

        if selected_file:
            df_csv = None

            if selected_file:
                if selected_file.endswith((".xlsx", ".xls")):
                    try:
                        df_csv = pd.read_excel(selected_file)
                    except Exception as e:
                        st.error(f"Excel íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
                else:
                    for enc in ["utf-8-sig", "utf-8", "cp949", "euc-kr"]:
                        try:
                            df_csv = pd.read_csv(selected_file, encoding=enc)
                            break
                        except (UnicodeDecodeError, UnicodeError):
                            continue

            if df_csv is None:
                st.error("íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í˜•ì‹ì´ë‚˜ ì¸ì½”ë”©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            else:
                display_name = _basename(selected_file)
                st.subheader(f"{display_name}")

                # ìš”ì•½ ì •ë³´
                col_info1, col_info2, col_info3 = st.columns(3)
                with col_info1:
                    st.metric("ì´ ì¡°ë¬¸ ìˆ˜", len(df_csv))
                with col_info2:
                    if "êµ­ê°€" in df_csv.columns:
                        st.metric("êµ­ê°€", df_csv["êµ­ê°€"].iloc[0] if len(df_csv) > 0 else "-")
                with col_info3:
                    if "ë§¤ì¹­ ì ìˆ˜" in df_csv.columns:
                        scores = pd.to_numeric(df_csv["ë§¤ì¹­ ì ìˆ˜"], errors="coerce")
                        avg_score = scores.mean()
                        st.metric("í‰ê·  ë§¤ì¹­ ì ìˆ˜", f"{avg_score:.3f}" if pd.notna(avg_score) else "-")

                st.divider()

                df_filtered = df_csv.copy()

                # 'ì „ë¬¸' í–‰ ì œì™¸
                if "ì¡°ë¬¸" in df_filtered.columns:
                    df_filtered = df_filtered[df_filtered["ì¡°ë¬¸"] != "ì „ë¬¸"]
                elif "ì¡°ë¬¸ë²ˆí˜¸" in df_filtered.columns:
                    # êµ¬ì¡°í™” ë°ì´í„°ëŠ” ì „ë¬¸ì´ ë”°ë¡œ ì—†ìœ¼ë¯€ë¡œ ìŠ¤í‚µ
                    pass

                st.caption(f"í‘œì‹œ ì¤‘: {len(df_filtered)}ê±´ / ì „ì²´ {len(df_csv)}ê±´")

                # ë³´ê¸° ëª¨ë“œ ì„ íƒ
                view_mode = st.radio(
                    "ë³´ê¸° ëª¨ë“œ", ["ì¡°ë¬¸ë³„ ìƒì„¸ ë³´ê¸°", "ì „ì²´ ë³´ê¸° (ë³µì‚¬ìš©)"],
                    horizontal=True, key="csv_view_mode",
                )

                st.markdown(DETAIL_STYLE, unsafe_allow_html=True)

                csv_name = display_name.replace(".csv", "").replace(".xlsx", "")
                parts = csv_name.split("_", 2)
                foreign_law_name = parts[2] if len(parts) >= 3 else csv_name

                if view_mode == "ì „ì²´ ë³´ê¸° (ë³µì‚¬ìš©)":
                    # â”€â”€ ì „ì²´ ë³´ê¸°: 3ì—´ ì •ë ¬ í…Œì´ë¸” â”€â”€
                    st.subheader("ì „ì²´ ë³´ê¸°")

                    # ë§¤ì¹­ ì •ë³´ ì»¬ëŸ¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
                    has_matching = "ìœ ì‚¬ í•œêµ­ë²•" in df_filtered.columns

                    table_html = """<style>
.fullview-table { width:100%; border-collapse:collapse; table-layout:fixed; font-family:inherit; }
.fullview-table th { background:#f0f0f0; padding:10px 12px; border:1px solid #ccc;
    text-align:left; position:sticky; top:0; z-index:1; font-size:0.9em; }
.fullview-table td { padding:10px 12px; border:1px solid #ccc; vertical-align:top;
    white-space:pre-wrap; word-break:break-word; font-size:0.88em; line-height:1.6; }
.fullview-table tr:nth-child(even) td { background:#f9f9f9; }
.col-id { width:8%; } .col-text { width:30%; } .col-text-narrow { width:22%; } .col-korean { width:22%; }
</style>
<table class="fullview-table">
                    <colgroup>
                        <col class="col-id">"""

                    if has_matching:
                        # í•œêµ­ë²•ì´ ìˆì„ ë•Œ: ê° í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ë„ˆë¹„ë¥¼ ì¤„ì„
                        table_html += '<col class="col-text-narrow"><col class="col-text-narrow"><col class="col-text-narrow"><col class="col-korean">'
                    else:
                        # í•œêµ­ë²•ì´ ì—†ì„ ë•Œ: ê¸°ì¡´ ë„ˆë¹„ ìœ ì§€
                        table_html += '<col class="col-text"><col class="col-text"><col class="col-text">'

                    table_html += """
                    </colgroup>
                    <thead><tr>
                        <th>ì¡°ë¬¸</th><th style="color:#8b2240">ì›ë¬¸</th>
                        <th style="color:#b8860b">Gemini ë²ˆì—­</th>
                        <th style="color:#6e1a33">Claude ë²ˆì—­</th>"""

                    if has_matching:
                        table_html += '<th style="color:#a0522d">ìœ ì‚¬ í•œêµ­ë²•</th>'

                    table_html += """
                    </tr></thead><tbody>"""

                    full_original = []
                    full_gemini = []
                    full_claude = []
                    full_korean = []

                    for _, row in df_filtered.iterrows():
                        # ì¡°ë¬¸ ID êµ¬ì„±: êµ¬ì¡°í™”ëœ ê²½ìš° ì¡°ë¬¸ë²ˆí˜¸, ì•„ë‹ˆë©´ "ì¡°ë¬¸" ì»¬ëŸ¼
                        if "ì¡°ë¬¸ë²ˆí˜¸" in row.index and pd.notna(row.get("ì¡°ë¬¸ë²ˆí˜¸")):
                            aid = _article_num_display(str(row['ì¡°ë¬¸ë²ˆí˜¸']))
                        else:
                            aid = str(row.get("ì¡°ë¬¸", ""))

                        orig = _clean_text(str(row.get("ì›ë¬¸", ""))) if pd.notna(row.get("ì›ë¬¸")) else ""
                        gem = _clean_text(_clean_translation_output(str(row.get("Gemini ë²ˆì—­", "")))) if pd.notna(row.get("Gemini ë²ˆì—­")) else ""
                        cla = _clean_text(_clean_translation_output(str(row.get("Claude ë²ˆì—­", "")))) if pd.notna(row.get("Claude ë²ˆì—­")) else ""

                        full_original.append(f"[{aid}]\n{orig}")
                        full_gemini.append(f"[{aid}]\n{gem}")
                        full_claude.append(f"[{aid}]\n{cla}")

                        # í•œêµ­ë²• ë§¤ì¹­ ì •ë³´
                        korean_info = ""
                        if has_matching:
                            similar_korean = str(row.get("ìœ ì‚¬ í•œêµ­ë²•", "")) if pd.notna(row.get("ìœ ì‚¬ í•œêµ­ë²•")) else ""

                            if similar_korean and similar_korean != "-":
                                korean_info = f"{_esc(similar_korean)}"

                            full_korean.append(f"[{aid}] {similar_korean}")

                        table_html += f"<tr><td><strong>{_esc(aid)}</strong></td>"
                        table_html += f"<td>{_esc(orig)}</td>"
                        table_html += f"<td>{_esc(gem)}</td>"
                        table_html += f"<td>{_esc(cla)}</td>"

                        if has_matching:
                            table_html += f"<td>{korean_info}</td>"

                        table_html += "</tr>"

                    table_html += "</tbody></table>"
                    st.html(table_html)

                    # í…ìŠ¤íŠ¸ ë³µì‚¬ìš© ì˜ì—­
                    st.divider()
                    st.subheader("í…ìŠ¤íŠ¸ ë³µì‚¬")

                    if has_matching and full_korean:
                        # ë§¤ì¹­ ì •ë³´ê°€ ìˆìœ¼ë©´ 4ì—´ë¡œ í‘œì‹œ
                        copy_col1, copy_col2, copy_col3, copy_col4 = st.columns(4)
                        with copy_col1:
                            st.text_area("ì›ë¬¸ ì „ì²´", "\n\n".join(full_original), height=400, key="copy_orig")
                        with copy_col2:
                            st.text_area("Gemini ë²ˆì—­ ì „ì²´", "\n\n".join(full_gemini), height=400, key="copy_gem")
                        with copy_col3:
                            st.text_area("Claude ë²ˆì—­ ì „ì²´", "\n\n".join(full_claude), height=400, key="copy_claude")
                        with copy_col4:
                            st.text_area("ìœ ì‚¬ í•œêµ­ë²• ì „ì²´", "\n\n".join(full_korean), height=400, key="copy_korean")
                    else:
                        # ë§¤ì¹­ ì •ë³´ê°€ ì—†ìœ¼ë©´ 3ì—´ë¡œ í‘œì‹œ
                        copy_col1, copy_col2, copy_col3 = st.columns(3)
                        with copy_col1:
                            st.text_area("ì›ë¬¸ ì „ì²´", "\n\n".join(full_original), height=400, key="copy_orig")
                        with copy_col2:
                            st.text_area("Gemini ë²ˆì—­ ì „ì²´", "\n\n".join(full_gemini), height=400, key="copy_gem")
                        with copy_col3:
                            st.text_area("Claude ë²ˆì—­ ì „ì²´", "\n\n".join(full_claude), height=400, key="copy_claude")

                else:
                    # â”€â”€ ì¡°ë¬¸ë³„ ìƒì„¸ ë³´ê¸° â”€â”€
                    st.subheader("ì¡°ë¬¸ë³„ ìƒì„¸ ë³´ê¸°")

                    has_structured = "ì¡°ë¬¸ë²ˆí˜¸" in df_filtered.columns

                    for idx, row in df_filtered.iterrows():
                        country_name = row.get("êµ­ê°€", "") if "êµ­ê°€" in row.index else ""

                        # êµ¬ì¡° ì •ë³´ êµ¬ì„±
                        structure_info = []
                        if has_structured:
                            if country_name:
                                structure_info.append(country_name)
                            elif foreign_law_name:
                                structure_info.append(foreign_law_name)
                            if "í¸" in row.index and pd.notna(row.get("í¸")) and str(row["í¸"]).strip():
                                structure_info.append(str(row["í¸"]))
                            if "ì¥" in row.index and pd.notna(row.get("ì¥")) and str(row["ì¥"]).strip():
                                structure_info.append(str(row["ì¥"]))
                            if "ì ˆ" in row.index and pd.notna(row.get("ì ˆ")) and str(row["ì ˆ"]).strip():
                                structure_info.append(str(row["ì ˆ"]))

                            # ì¡°ë¬¸ë²ˆí˜¸ í‘œì‹œ: Section/Article/Â§ ì ‘ë‘ì–´ ì œê±°í•˜ê³  ìˆ«ìë§Œ í‘œì‹œ
                            article_num = str(row.get('ì¡°ë¬¸ë²ˆí˜¸', ''))
                            art_label = _article_num_display(article_num)

                            if "ì¡°ë¬¸ì œëª©" in row.index and pd.notna(row.get("ì¡°ë¬¸ì œëª©")) and str(row["ì¡°ë¬¸ì œëª©"]).strip():
                                art_label += f" {row['ì¡°ë¬¸ì œëª©']}"
                            structure_info.append(art_label)
                        else:
                            article_id = row.get("ì¡°ë¬¸", f"í–‰ {idx}")
                            if country_name:
                                structure_info.append(f"{country_name} {foreign_law_name} â€” {article_id}")
                            else:
                                structure_info.append(f"{foreign_law_name} â€” {article_id}")

                        structure_text = " â€” ".join(structure_info)
                        original_text = _esc(_clean_text(str(row["ì›ë¬¸"]))) if "ì›ë¬¸" in row.index and pd.notna(row["ì›ë¬¸"]) else ""
                        gemini_text = _esc(_clean_text(_clean_translation_output(str(row["Gemini ë²ˆì—­"])))) if "Gemini ë²ˆì—­" in row.index and pd.notna(row.get("Gemini ë²ˆì—­")) else ""
                        claude_text = _esc(_clean_text(_clean_translation_output(str(row["Claude ë²ˆì—­"])))) if "Claude ë²ˆì—­" in row.index and pd.notna(row.get("Claude ë²ˆì—­")) else ""

                        # êµ¬ì¡° ì •ë³´ë¥¼ ìœ„ì— í‘œì‹œ
                        st.markdown(f'<div class="article-title">{structure_text}</div>', unsafe_allow_html=True)
                        st.markdown(f"""
                        <div class="article-row">
                            <div class="article-col col-original"><div class="article-col-header">ì›ë¬¸</div><div class="article-col-body">{original_text}</div></div>
                            <div class="article-col col-gemini"><div class="article-col-header">Gemini ë²ˆì—­</div><div class="article-col-body">{gemini_text}</div></div>
                            <div class="article-col col-claude"><div class="article-col-header">Claude ë²ˆì—­</div><div class="article-col-body">{claude_text}</div></div>
                        </div>
                        """, unsafe_allow_html=True)

                        # ìœ ì‚¬ í•œêµ­ë²•
                        if "ìœ ì‚¬ í•œêµ­ë²•" in row.index and pd.notna(row.get("ìœ ì‚¬ í•œêµ­ë²•")) and str(row["ìœ ì‚¬ í•œêµ­ë²•"]).strip():
                            korean_article = str(row["ìœ ì‚¬ í•œêµ­ë²•"])
                            if not korean_article.startswith("["):
                                korean_article = f"[í•œêµ­ë²•] {korean_article}"
                            score_str = f" (ìœ ì‚¬ë„: {row['ë§¤ì¹­ ì ìˆ˜']})" if "ë§¤ì¹­ ì ìˆ˜" in row.index and pd.notna(row.get("ë§¤ì¹­ ì ìˆ˜")) else ""
                            korean_text_html = ""
                            if "í•œêµ­ë²• ì¡°ë¬¸ ë‚´ìš©" in row.index and pd.notna(row.get("í•œêµ­ë²• ì¡°ë¬¸ ë‚´ìš©")) and str(row["í•œêµ­ë²• ì¡°ë¬¸ ë‚´ìš©"]).strip():
                                korean_text_html = f"<br><div style='margin-top:6px;white-space:pre-wrap;color:#333;'>{_esc(_clean_text(str(row['í•œêµ­ë²• ì¡°ë¬¸ ë‚´ìš©'])))}</div>"
                            st.markdown(f'<div class="korea-law-box"><strong>ìœ ì‚¬ í•œêµ­ë²•: {korean_article}{score_str}</strong>{korean_text_html}</div>', unsafe_allow_html=True)

                            # ë§¤ì¹­ ì´ìœ 
                            if "ë§¤ì¹­ ì´ìœ " in row.index and pd.notna(row.get("ë§¤ì¹­ ì´ìœ ")) and str(row["ë§¤ì¹­ ì´ìœ "]).strip():
                                st.markdown(f'<div class="diff-box"><strong>ë§¤ì¹­ ì´ìœ </strong><br>{_esc(str(row["ë§¤ì¹­ ì´ìœ "]))}</div>', unsafe_allow_html=True)

                        st.markdown("<br>", unsafe_allow_html=True)
                        st.divider()

                # Excel ë‹¤ìš´ë¡œë“œ
                st.divider()
                download_base = csv_name

                excel_buf = io.BytesIO()
                with pd.ExcelWriter(excel_buf, engine="openpyxl") as ew:
                    df_filtered.to_excel(ew, index=False, sheet_name="ë²ˆì—­ê²°ê³¼")

                    # ì…€ í¬ë§·íŒ…: ì¤„ë°”ê¿ˆ í‘œì‹œ
                    worksheet = ew.sheets["ë²ˆì—­ê²°ê³¼"]
                    for row in worksheet.iter_rows():
                        for cell in row:
                            cell.alignment = Alignment(wrap_text=True, vertical='top')

                excel_download = excel_buf.getvalue()

                st.download_button("Excel ë‹¤ìš´ë¡œë“œ", excel_download, f"{download_base}.xlsx",
                                   "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", key="xlsx_dl")
